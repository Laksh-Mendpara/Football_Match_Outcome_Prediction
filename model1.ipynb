{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchensemble.utils.logging import set_logger\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torchensemble\n",
    "from enum import Enum \n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>...</th>\n",
       "      <th>league_id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_long_name</th>\n",
       "      <th>home_team_short_name</th>\n",
       "      <th>away_team_long_name</th>\n",
       "      <th>away_team_short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>6067</td>\n",
       "      <td>E0</td>\n",
       "      <td>5/11/2016 0:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>30</td>\n",
       "      <td>5/11/2016 0:00</td>\n",
       "      <td>8650</td>\n",
       "      <td>8455</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>LIV</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>6069</td>\n",
       "      <td>E0</td>\n",
       "      <td>5/11/2016 0:00</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Everton</td>\n",
       "      <td>H</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>30</td>\n",
       "      <td>5/11/2016 0:00</td>\n",
       "      <td>8472</td>\n",
       "      <td>8668</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>SUN</td>\n",
       "      <td>Everton</td>\n",
       "      <td>EVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>6070</td>\n",
       "      <td>E0</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>38</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>9825</td>\n",
       "      <td>10252</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>ARS</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>AVL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>6074</td>\n",
       "      <td>E0</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>38</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>8466</td>\n",
       "      <td>9826</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>SOU</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>CRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6077</td>\n",
       "      <td>E0</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>38</td>\n",
       "      <td>5/15/2016 0:00</td>\n",
       "      <td>9817</td>\n",
       "      <td>8472</td>\n",
       "      <td>Watford</td>\n",
       "      <td>WAT</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>SUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HH Div            Date     HomeTeam        AwayTeam FTR  HST  AST  HC  \\\n",
       "536  6067  E0  5/11/2016 0:00    Liverpool         Chelsea   D    9    7   7   \n",
       "537  6069  E0  5/11/2016 0:00   Sunderland         Everton   H    8    6   5   \n",
       "538  6070  E0  5/15/2016 0:00      Arsenal     Aston Villa   H    7    2   5   \n",
       "539  6074  E0  5/15/2016 0:00  Southampton  Crystal Palace   H    5    4   2   \n",
       "540  6077  E0  5/15/2016 0:00      Watford      Sunderland   D    6    4   7   \n",
       "\n",
       "     AC  ...  league_id     season  stage            date  home_team_api_id  \\\n",
       "536   3  ...       1729  2015/2016     30  5/11/2016 0:00              8650   \n",
       "537   5  ...       1729  2015/2016     30  5/11/2016 0:00              8472   \n",
       "538   4  ...       1729  2015/2016     38  5/15/2016 0:00              9825   \n",
       "539   5  ...       1729  2015/2016     38  5/15/2016 0:00              8466   \n",
       "540   4  ...       1729  2015/2016     38  5/15/2016 0:00              9817   \n",
       "\n",
       "     away_team_api_id  home_team_long_name  home_team_short_name  \\\n",
       "536              8455            Liverpool                   LIV   \n",
       "537              8668           Sunderland                   SUN   \n",
       "538             10252              Arsenal                   ARS   \n",
       "539              9826          Southampton                   SOU   \n",
       "540              8472              Watford                   WAT   \n",
       "\n",
       "     away_team_long_name  away_team_short_name  \n",
       "536              Chelsea                   CHE  \n",
       "537              Everton                   EVE  \n",
       "538          Aston Villa                   AVL  \n",
       "539       Crystal Palace                   CRY  \n",
       "540           Sunderland                   SUN  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv', index_col=None);\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HAS</th>\n",
       "      <th>HDS</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ADS</th>\n",
       "      <th>home_team_buildUpPlaySpeed</th>\n",
       "      <th>home_team_buildUpPlayPassing</th>\n",
       "      <th>...</th>\n",
       "      <th>away_player_3_overall_rating</th>\n",
       "      <th>away_player_4_overall_rating</th>\n",
       "      <th>away_player_5_overall_rating</th>\n",
       "      <th>away_player_6_overall_rating</th>\n",
       "      <th>away_player_7_overall_rating</th>\n",
       "      <th>away_player_8_overall_rating</th>\n",
       "      <th>away_player_9_overall_rating</th>\n",
       "      <th>away_player_10_overall_rating</th>\n",
       "      <th>away_player_11_overall_rating</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233395</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>1.389295</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>66</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>0.883299</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429960</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>1.082190</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.236911</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>0.128693</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.915866</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HST  AST  HC  AC       HAS       HDS       AAS       ADS  \\\n",
       "536    9    7   7   3  1.233395  0.690260  1.389295  0.619937   \n",
       "537    8    6   5   5  0.587536  0.883299  0.956420  0.896425   \n",
       "538    7    2   5   4  1.429960  0.739982  0.997368  1.082190   \n",
       "539    5    4   2   5  0.568096  0.552793  0.236911  0.259207   \n",
       "540    6    4   7   4  0.084242  0.128693  0.640538  0.915866   \n",
       "\n",
       "     home_team_buildUpPlaySpeed  home_team_buildUpPlayPassing  ...  \\\n",
       "536                          66                            45  ...   \n",
       "537                          43                            51  ...   \n",
       "538                          59                            30  ...   \n",
       "539                          52                            46  ...   \n",
       "540                          61                            52  ...   \n",
       "\n",
       "     away_player_3_overall_rating  away_player_4_overall_rating  \\\n",
       "536                            82                            77   \n",
       "537                            77                            75   \n",
       "538                            74                            61   \n",
       "539                            71                            74   \n",
       "540                            74                            75   \n",
       "\n",
       "     away_player_5_overall_rating  away_player_6_overall_rating  \\\n",
       "536                            77                            86   \n",
       "537                            82                            80   \n",
       "538                            73                            76   \n",
       "539                            75                            76   \n",
       "540                            59                            75   \n",
       "\n",
       "     away_player_7_overall_rating  away_player_8_overall_rating  \\\n",
       "536                            83                            83   \n",
       "537                            79                            80   \n",
       "538                            74                            75   \n",
       "539                            76                            75   \n",
       "540                            60                            79   \n",
       "\n",
       "     away_player_9_overall_rating  away_player_10_overall_rating  \\\n",
       "536                            88                             83   \n",
       "537                            80                             77   \n",
       "538                            72                             76   \n",
       "539                            71                             71   \n",
       "540                            67                             74   \n",
       "\n",
       "     away_player_11_overall_rating  outcome  \n",
       "536                             74     Draw  \n",
       "537                             82      Win  \n",
       "538                             75      Win  \n",
       "539                             78      Win  \n",
       "540                             76     Draw  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['HH', 'Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTR', 'Result', 'match_api_id', \\\n",
    "                      'home_team_goals_difference', 'away_team_goals_difference', \\\n",
    "                        'League_1729.0', 'League_4769.0', \\\n",
    "                        'League_7809.0', 'League_10257.0', 'League_13274.0', 'League_19694.0', 'League_21518.0', \\\n",
    "                            'country_id', 'league_id', 'season', 'stage', 'date', \\\n",
    "                                'home_team_api_id', 'home_team_long_name', 'home_team_short_name', \\\n",
    "                                    'away_team_api_id', 'away_team_long_name', 'away_team_short_name'], axis=1)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HAS</th>\n",
       "      <th>HDS</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ADS</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>...</th>\n",
       "      <th>away_player_3_overall_rating</th>\n",
       "      <th>away_player_4_overall_rating</th>\n",
       "      <th>away_player_5_overall_rating</th>\n",
       "      <th>away_player_6_overall_rating</th>\n",
       "      <th>away_player_7_overall_rating</th>\n",
       "      <th>away_player_8_overall_rating</th>\n",
       "      <th>away_player_9_overall_rating</th>\n",
       "      <th>away_player_10_overall_rating</th>\n",
       "      <th>away_player_11_overall_rating</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233395</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>1.389295</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>0.883299</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429960</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>1.082190</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.236911</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>1.36</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>0.128693</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.915866</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HST  AST  HC  AC       HAS       HDS       AAS       ADS  B365H  B365D  \\\n",
       "536    9    7   7   3  1.233395  0.690260  1.389295  0.619937   2.00   3.80   \n",
       "537    8    6   5   5  0.587536  0.883299  0.956420  0.896425   1.75   4.00   \n",
       "538    7    2   5   4  1.429960  0.739982  0.997368  1.082190   1.17   9.00   \n",
       "539    5    4   2   5  0.568096  0.552793  0.236911  0.259207   1.36   5.50   \n",
       "540    6    4   7   4  0.084242  0.128693  0.640538  0.915866   2.05   3.75   \n",
       "\n",
       "     ...  away_player_3_overall_rating  away_player_4_overall_rating  \\\n",
       "536  ...                            82                            77   \n",
       "537  ...                            77                            75   \n",
       "538  ...                            74                            61   \n",
       "539  ...                            71                            74   \n",
       "540  ...                            74                            75   \n",
       "\n",
       "     away_player_5_overall_rating  away_player_6_overall_rating  \\\n",
       "536                            77                            86   \n",
       "537                            82                            80   \n",
       "538                            73                            76   \n",
       "539                            75                            76   \n",
       "540                            59                            75   \n",
       "\n",
       "     away_player_7_overall_rating  away_player_8_overall_rating  \\\n",
       "536                            83                            83   \n",
       "537                            79                            80   \n",
       "538                            74                            75   \n",
       "539                            76                            75   \n",
       "540                            60                            79   \n",
       "\n",
       "     away_player_9_overall_rating  away_player_10_overall_rating  \\\n",
       "536                            88                             83   \n",
       "537                            80                             77   \n",
       "538                            72                             76   \n",
       "539                            71                             71   \n",
       "540                            67                             74   \n",
       "\n",
       "     away_player_11_overall_rating  outcome  \n",
       "536                             74     Draw  \n",
       "537                             82      Win  \n",
       "538                             75      Win  \n",
       "539                             78      Win  \n",
       "540                             76     Draw  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['home_team_buildUpPlaySpeed', 'home_team_buildUpPlayPassing',\n",
    "       'home_team_chanceCreationPassing', 'home_team_chanceCreationCrossing',\n",
    "       'home_team_chanceCreationShooting', 'home_team_defencePressure',\n",
    "       'home_team_defenceAggression', 'home_team_defenceTeamWidth',\n",
    "       'home_team_avg_shots', 'home_team_avg_corners', 'home_team_avg_crosses',\n",
    "       'away_team_buildUpPlaySpeed', 'away_team_buildUpPlayPassing',\n",
    "       'away_team_chanceCreationPassing', 'away_team_chanceCreationCrossing',\n",
    "       'away_team_chanceCreationShooting', 'away_team_defencePressure',\n",
    "       'away_team_defenceAggression', 'away_team_defenceTeamWidth',\n",
    "       'away_team_avg_shots', 'away_team_avg_corners', 'away_team_avg_crosses',\n",
    "       'games_won_home_team', 'games_won_away_team', 'games_against_won',\n",
    "       'games_against_lost'], axis=1)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HST', 'AST', 'HC', 'AC', 'HAS', 'HDS', 'AAS', 'ADS', 'B365H', 'B365D',\n",
       "       'B365A', 'home_player_1_overall_rating', 'home_player_2_overall_rating',\n",
       "       'home_player_3_overall_rating', 'home_player_4_overall_rating',\n",
       "       'home_player_5_overall_rating', 'home_player_6_overall_rating',\n",
       "       'home_player_7_overall_rating', 'home_player_8_overall_rating',\n",
       "       'home_player_9_overall_rating', 'home_player_10_overall_rating',\n",
       "       'home_player_11_overall_rating', 'away_player_1_overall_rating',\n",
       "       'away_player_2_overall_rating', 'away_player_3_overall_rating',\n",
       "       'away_player_4_overall_rating', 'away_player_5_overall_rating',\n",
       "       'away_player_6_overall_rating', 'away_player_7_overall_rating',\n",
       "       'away_player_8_overall_rating', 'away_player_9_overall_rating',\n",
       "       'away_player_10_overall_rating', 'away_player_11_overall_rating',\n",
       "       'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_player_1_overall_rating</th>\n",
       "      <th>home_player_2_overall_rating</th>\n",
       "      <th>home_player_3_overall_rating</th>\n",
       "      <th>home_player_4_overall_rating</th>\n",
       "      <th>home_player_5_overall_rating</th>\n",
       "      <th>home_player_6_overall_rating</th>\n",
       "      <th>home_player_7_overall_rating</th>\n",
       "      <th>home_player_8_overall_rating</th>\n",
       "      <th>home_player_9_overall_rating</th>\n",
       "      <th>home_player_10_overall_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>away_player_2_overall_rating</th>\n",
       "      <th>away_player_3_overall_rating</th>\n",
       "      <th>away_player_4_overall_rating</th>\n",
       "      <th>away_player_5_overall_rating</th>\n",
       "      <th>away_player_6_overall_rating</th>\n",
       "      <th>away_player_7_overall_rating</th>\n",
       "      <th>away_player_8_overall_rating</th>\n",
       "      <th>away_player_9_overall_rating</th>\n",
       "      <th>away_player_10_overall_rating</th>\n",
       "      <th>away_player_11_overall_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_player_1_overall_rating  home_player_2_overall_rating  \\\n",
       "536                            78                            80   \n",
       "537                            74                            71   \n",
       "538                            86                            77   \n",
       "539                            76                            69   \n",
       "540                            76                            72   \n",
       "\n",
       "     home_player_3_overall_rating  home_player_4_overall_rating  \\\n",
       "536                            79                            78   \n",
       "537                            74                            76   \n",
       "538                            84                            78   \n",
       "539                            77                            81   \n",
       "540                            76                            74   \n",
       "\n",
       "     home_player_5_overall_rating  home_player_6_overall_rating  \\\n",
       "536                            77                            80   \n",
       "537                            74                            75   \n",
       "538                            80                            79   \n",
       "539                            78                            73   \n",
       "540                            72                            72   \n",
       "\n",
       "     home_player_7_overall_rating  home_player_8_overall_rating  \\\n",
       "536                            75                            80   \n",
       "537                            75                            77   \n",
       "538                            81                            86   \n",
       "539                            77                            78   \n",
       "540                            70                            71   \n",
       "\n",
       "     home_player_9_overall_rating  home_player_10_overall_rating  ...  \\\n",
       "536                            82                             84  ...   \n",
       "537                            78                             78  ...   \n",
       "538                            88                             85  ...   \n",
       "539                            76                             78  ...   \n",
       "540                            75                             77  ...   \n",
       "\n",
       "     away_player_2_overall_rating  away_player_3_overall_rating  \\\n",
       "536                            82                            82   \n",
       "537                            63                            77   \n",
       "538                            58                            74   \n",
       "539                            76                            71   \n",
       "540                            71                            74   \n",
       "\n",
       "     away_player_4_overall_rating  away_player_5_overall_rating  \\\n",
       "536                            77                            77   \n",
       "537                            75                            82   \n",
       "538                            61                            73   \n",
       "539                            74                            75   \n",
       "540                            75                            59   \n",
       "\n",
       "     away_player_6_overall_rating  away_player_7_overall_rating  \\\n",
       "536                            86                            83   \n",
       "537                            80                            79   \n",
       "538                            76                            74   \n",
       "539                            76                            76   \n",
       "540                            75                            60   \n",
       "\n",
       "     away_player_8_overall_rating  away_player_9_overall_rating  \\\n",
       "536                            83                            88   \n",
       "537                            80                            80   \n",
       "538                            75                            72   \n",
       "539                            75                            71   \n",
       "540                            79                            67   \n",
       "\n",
       "     away_player_10_overall_rating  away_player_11_overall_rating  \n",
       "536                             83                             74  \n",
       "537                             77                             82  \n",
       "538                             76                             75  \n",
       "539                             71                             78  \n",
       "540                             74                             76  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df[['home_player_1_overall_rating', 'home_player_2_overall_rating',\n",
    "       'home_player_3_overall_rating', 'home_player_4_overall_rating',\n",
    "       'home_player_5_overall_rating', 'home_player_6_overall_rating',\n",
    "       'home_player_7_overall_rating', 'home_player_8_overall_rating',\n",
    "       'home_player_9_overall_rating', 'home_player_10_overall_rating',\n",
    "       'home_player_11_overall_rating', 'away_player_1_overall_rating',\n",
    "       'away_player_2_overall_rating', 'away_player_3_overall_rating',\n",
    "       'away_player_4_overall_rating', 'away_player_5_overall_rating',\n",
    "       'away_player_6_overall_rating', 'away_player_7_overall_rating',\n",
    "       'away_player_8_overall_rating', 'away_player_9_overall_rating',\n",
    "       'away_player_10_overall_rating', 'away_player_11_overall_rating']]\n",
    "df_temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['home_player_1_overall_rating', 'home_player_2_overall_rating',\n",
    "       'home_player_3_overall_rating', 'home_player_4_overall_rating',\n",
    "       'home_player_5_overall_rating', 'home_player_6_overall_rating',\n",
    "       'home_player_7_overall_rating', 'home_player_8_overall_rating',\n",
    "       'home_player_9_overall_rating', 'home_player_10_overall_rating',\n",
    "       'home_player_11_overall_rating', 'away_player_1_overall_rating',\n",
    "       'away_player_2_overall_rating', 'away_player_3_overall_rating',\n",
    "       'away_player_4_overall_rating', 'away_player_5_overall_rating',\n",
    "       'away_player_6_overall_rating', 'away_player_7_overall_rating',\n",
    "       'away_player_8_overall_rating', 'away_player_9_overall_rating',\n",
    "       'away_player_10_overall_rating', 'away_player_11_overall_rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816593758294258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame(df_temp)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(df_temp)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pca.transform(df_temp)\n",
    "df_temp = pd.DataFrame(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome\n",
       "536        1\n",
       "537        2\n",
       "538        2\n",
       "539        2\n",
       "540        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = df['outcome']\n",
    "\n",
    "def encode(data):\n",
    "    # encode the class label\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    if(data=='Win'):\n",
    "        return 2;\n",
    "    if(data=='Draw'):\n",
    "        return 1;\n",
    "    if(data=='Defeat'):\n",
    "        return 0;\n",
    "\n",
    "outcomes = outcomes.apply(encode)\n",
    "outcomes = pd.DataFrame(outcomes)\n",
    "outcomes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HAS</th>\n",
       "      <th>HDS</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ADS</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233395</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>1.389295</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>0.883299</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429960</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>1.082190</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.00</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.236911</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>1.36</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>0.128693</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.915866</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HST  AST  HC  AC       HAS       HDS       AAS       ADS  B365H  B365D  \\\n",
       "536    9    7   7   3  1.233395  0.690260  1.389295  0.619937   2.00   3.80   \n",
       "537    8    6   5   5  0.587536  0.883299  0.956420  0.896425   1.75   4.00   \n",
       "538    7    2   5   4  1.429960  0.739982  0.997368  1.082190   1.17   9.00   \n",
       "539    5    4   2   5  0.568096  0.552793  0.236911  0.259207   1.36   5.50   \n",
       "540    6    4   7   4  0.084242  0.128693  0.640538  0.915866   2.05   3.75   \n",
       "\n",
       "     B365A  \n",
       "536    3.8  \n",
       "537    5.0  \n",
       "538   17.0  \n",
       "539    9.0  \n",
       "540    3.7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['outcome'], axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>-1.536202</td>\n",
       "      <td>-18.046928</td>\n",
       "      <td>2.079882</td>\n",
       "      <td>-1.449557</td>\n",
       "      <td>4.533621</td>\n",
       "      <td>1.613389</td>\n",
       "      <td>1.551730</td>\n",
       "      <td>0.796618</td>\n",
       "      <td>1.686251</td>\n",
       "      <td>-3.216649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>-4.273281</td>\n",
       "      <td>1.416371</td>\n",
       "      <td>2.650995</td>\n",
       "      <td>5.342347</td>\n",
       "      <td>-9.928085</td>\n",
       "      <td>3.055038</td>\n",
       "      <td>2.379932</td>\n",
       "      <td>-1.687633</td>\n",
       "      <td>-5.527952</td>\n",
       "      <td>-2.692120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>25.160587</td>\n",
       "      <td>3.628761</td>\n",
       "      <td>5.257006</td>\n",
       "      <td>8.091025</td>\n",
       "      <td>-2.874321</td>\n",
       "      <td>0.903967</td>\n",
       "      <td>-1.674997</td>\n",
       "      <td>-3.331742</td>\n",
       "      <td>-4.389955</td>\n",
       "      <td>1.534296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3.191486</td>\n",
       "      <td>8.057030</td>\n",
       "      <td>-9.595790</td>\n",
       "      <td>-1.228450</td>\n",
       "      <td>-2.760842</td>\n",
       "      <td>2.197465</td>\n",
       "      <td>-4.515607</td>\n",
       "      <td>1.653777</td>\n",
       "      <td>-0.700779</td>\n",
       "      <td>0.527612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2.848854</td>\n",
       "      <td>21.863728</td>\n",
       "      <td>3.613288</td>\n",
       "      <td>-5.136899</td>\n",
       "      <td>1.535456</td>\n",
       "      <td>-3.508839</td>\n",
       "      <td>6.562930</td>\n",
       "      <td>2.960677</td>\n",
       "      <td>9.986415</td>\n",
       "      <td>6.961477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5         6  \\\n",
       "536  -1.536202 -18.046928  2.079882 -1.449557  4.533621  1.613389  1.551730   \n",
       "537  -4.273281   1.416371  2.650995  5.342347 -9.928085  3.055038  2.379932   \n",
       "538  25.160587   3.628761  5.257006  8.091025 -2.874321  0.903967 -1.674997   \n",
       "539   3.191486   8.057030 -9.595790 -1.228450 -2.760842  2.197465 -4.515607   \n",
       "540   2.848854  21.863728  3.613288 -5.136899  1.535456 -3.508839  6.562930   \n",
       "\n",
       "            7         8         9  \n",
       "536  0.796618  1.686251 -3.216649  \n",
       "537 -1.687633 -5.527952 -2.692120  \n",
       "538 -3.331742 -4.389955  1.534296  \n",
       "539  1.653777 -0.700779  0.527612  \n",
       "540  2.960677  9.986415  6.961477  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HAS</th>\n",
       "      <th>HDS</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ADS</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233395</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>1.389295</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.536202</td>\n",
       "      <td>-18.046928</td>\n",
       "      <td>2.079882</td>\n",
       "      <td>-1.449557</td>\n",
       "      <td>4.533621</td>\n",
       "      <td>1.613389</td>\n",
       "      <td>1.551730</td>\n",
       "      <td>0.796618</td>\n",
       "      <td>1.686251</td>\n",
       "      <td>-3.216649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>0.883299</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.273281</td>\n",
       "      <td>1.416371</td>\n",
       "      <td>2.650995</td>\n",
       "      <td>5.342347</td>\n",
       "      <td>-9.928085</td>\n",
       "      <td>3.055038</td>\n",
       "      <td>2.379932</td>\n",
       "      <td>-1.687633</td>\n",
       "      <td>-5.527952</td>\n",
       "      <td>-2.692120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429960</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>1.082190</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.160587</td>\n",
       "      <td>3.628761</td>\n",
       "      <td>5.257006</td>\n",
       "      <td>8.091025</td>\n",
       "      <td>-2.874321</td>\n",
       "      <td>0.903967</td>\n",
       "      <td>-1.674997</td>\n",
       "      <td>-3.331742</td>\n",
       "      <td>-4.389955</td>\n",
       "      <td>1.534296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.236911</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>1.36</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.191486</td>\n",
       "      <td>8.057030</td>\n",
       "      <td>-9.595790</td>\n",
       "      <td>-1.228450</td>\n",
       "      <td>-2.760842</td>\n",
       "      <td>2.197465</td>\n",
       "      <td>-4.515607</td>\n",
       "      <td>1.653777</td>\n",
       "      <td>-0.700779</td>\n",
       "      <td>0.527612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>0.128693</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.915866</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848854</td>\n",
       "      <td>21.863728</td>\n",
       "      <td>3.613288</td>\n",
       "      <td>-5.136899</td>\n",
       "      <td>1.535456</td>\n",
       "      <td>-3.508839</td>\n",
       "      <td>6.562930</td>\n",
       "      <td>2.960677</td>\n",
       "      <td>9.986415</td>\n",
       "      <td>6.961477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HST  AST  HC  AC       HAS       HDS       AAS       ADS  B365H  B365D  \\\n",
       "536    9    7   7   3  1.233395  0.690260  1.389295  0.619937   2.00   3.80   \n",
       "537    8    6   5   5  0.587536  0.883299  0.956420  0.896425   1.75   4.00   \n",
       "538    7    2   5   4  1.429960  0.739982  0.997368  1.082190   1.17   9.00   \n",
       "539    5    4   2   5  0.568096  0.552793  0.236911  0.259207   1.36   5.50   \n",
       "540    6    4   7   4  0.084242  0.128693  0.640538  0.915866   2.05   3.75   \n",
       "\n",
       "     ...          0          1         2         3         4         5  \\\n",
       "536  ...  -1.536202 -18.046928  2.079882 -1.449557  4.533621  1.613389   \n",
       "537  ...  -4.273281   1.416371  2.650995  5.342347 -9.928085  3.055038   \n",
       "538  ...  25.160587   3.628761  5.257006  8.091025 -2.874321  0.903967   \n",
       "539  ...   3.191486   8.057030 -9.595790 -1.228450 -2.760842  2.197465   \n",
       "540  ...   2.848854  21.863728  3.613288 -5.136899  1.535456 -3.508839   \n",
       "\n",
       "            6         7         8         9  \n",
       "536  1.551730  0.796618  1.686251 -3.216649  \n",
       "537  2.379932 -1.687633 -5.527952 -2.692120  \n",
       "538 -1.674997 -3.331742 -4.389955  1.534296  \n",
       "539 -4.515607  1.653777 -0.700779  0.527612  \n",
       "540  6.562930  2.960677  9.986415  6.961477  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df_temp], axis = 1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HAS</th>\n",
       "      <th>HDS</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ADS</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233395</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>1.389295</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.536202</td>\n",
       "      <td>-18.046928</td>\n",
       "      <td>2.079882</td>\n",
       "      <td>-1.449557</td>\n",
       "      <td>4.533621</td>\n",
       "      <td>1.613389</td>\n",
       "      <td>1.551730</td>\n",
       "      <td>0.796618</td>\n",
       "      <td>1.686251</td>\n",
       "      <td>-3.216649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>0.883299</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.273281</td>\n",
       "      <td>1.416371</td>\n",
       "      <td>2.650995</td>\n",
       "      <td>5.342347</td>\n",
       "      <td>-9.928085</td>\n",
       "      <td>3.055038</td>\n",
       "      <td>2.379932</td>\n",
       "      <td>-1.687633</td>\n",
       "      <td>-5.527952</td>\n",
       "      <td>-2.692120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429960</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>1.082190</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.160587</td>\n",
       "      <td>3.628761</td>\n",
       "      <td>5.257006</td>\n",
       "      <td>8.091025</td>\n",
       "      <td>-2.874321</td>\n",
       "      <td>0.903967</td>\n",
       "      <td>-1.674997</td>\n",
       "      <td>-3.331742</td>\n",
       "      <td>-4.389955</td>\n",
       "      <td>1.534296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.236911</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>1.36</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.191486</td>\n",
       "      <td>8.057030</td>\n",
       "      <td>-9.595790</td>\n",
       "      <td>-1.228450</td>\n",
       "      <td>-2.760842</td>\n",
       "      <td>2.197465</td>\n",
       "      <td>-4.515607</td>\n",
       "      <td>1.653777</td>\n",
       "      <td>-0.700779</td>\n",
       "      <td>0.527612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>0.128693</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.915866</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848854</td>\n",
       "      <td>21.863728</td>\n",
       "      <td>3.613288</td>\n",
       "      <td>-5.136899</td>\n",
       "      <td>1.535456</td>\n",
       "      <td>-3.508839</td>\n",
       "      <td>6.562930</td>\n",
       "      <td>2.960677</td>\n",
       "      <td>9.986415</td>\n",
       "      <td>6.961477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HST  AST  HC  AC       HAS       HDS       AAS       ADS  B365H  B365D  \\\n",
       "536    9    7   7   3  1.233395  0.690260  1.389295  0.619937   2.00   3.80   \n",
       "537    8    6   5   5  0.587536  0.883299  0.956420  0.896425   1.75   4.00   \n",
       "538    7    2   5   4  1.429960  0.739982  0.997368  1.082190   1.17   9.00   \n",
       "539    5    4   2   5  0.568096  0.552793  0.236911  0.259207   1.36   5.50   \n",
       "540    6    4   7   4  0.084242  0.128693  0.640538  0.915866   2.05   3.75   \n",
       "\n",
       "     ...          0          1         2         3         4         5  \\\n",
       "536  ...  -1.536202 -18.046928  2.079882 -1.449557  4.533621  1.613389   \n",
       "537  ...  -4.273281   1.416371  2.650995  5.342347 -9.928085  3.055038   \n",
       "538  ...  25.160587   3.628761  5.257006  8.091025 -2.874321  0.903967   \n",
       "539  ...   3.191486   8.057030 -9.595790 -1.228450 -2.760842  2.197465   \n",
       "540  ...   2.848854  21.863728  3.613288 -5.136899  1.535456 -3.508839   \n",
       "\n",
       "            6         7         8         9  \n",
       "536  1.551730  0.796618  1.686251 -3.216649  \n",
       "537  2.379932 -1.687633 -5.527952 -2.692120  \n",
       "538 -1.674997 -3.331742 -4.389955  1.534296  \n",
       "539 -4.515607  1.653777 -0.700779  0.527612  \n",
       "540  6.562930  2.960677  9.986415  6.961477  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.astype(str)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = preprocessing.StandardScaler()\n",
    "scaling.fit(df)\n",
    "feature_data = scaling.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principal = PCA(n_components=20)\n",
    "# principal.fit(df)\n",
    "# principal.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = principal.transform(df)\n",
    "# df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "NUM_FEATURES= df.shape[1]\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(df, outcomes, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Set: (432, 21)\n",
      "X Test Set: (109, 21)\n",
      "y Train Set: (432, 1)\n",
      "y Test Set: (109, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Train Set: {train_data.shape}\")\n",
    "print(f\"X Test Set: {test_data.shape}\")\n",
    "print(f\"y Train Set: {train_targets.shape}\")\n",
    "print(f\"y Test Set: {test_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = np.array(data)\n",
    "        self.targets = np.array(targets)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_tensor = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(self.targets[idx], dtype=torch.long).squeeze()\n",
    "        return data_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.0000,  1.0000, 13.0000,  3.0000,  1.4040,  0.6932,  0.6464,  0.8597,\n",
       "          1.3000,  5.7500, 12.0000, 16.7362, -7.2678, -4.3147,  0.5221,  0.4566,\n",
       "          1.1773,  4.2474,  0.2326,  2.1076,  0.7199]),\n",
       " tensor(2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = 3\n",
    "        self.num_features = NUM_FEATURES\n",
    "\n",
    "        self.my_network = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(self.num_features, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(256, 500),\n",
    "            torch.nn.BatchNorm1d(500),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "\n",
    "            # 3rd hidden layer\n",
    "            torch.nn.Linear(500, 100),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.4),\n",
    "\n",
    "            # 4th hidden layer\n",
    "            torch.nn.Linear(100, 50),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            # 5th hidden layer\n",
    "            torch.nn.Linear(50, 20),\n",
    "            torch.nn.BatchNorm1d(20),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "\n",
    "            # output hidden layer\n",
    "            torch.nn.Linear(20, self.num_classes),\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.my_network(x)\n",
    "        probas = torch.softmax(logits, dim=1)\n",
    "        # prediction = torch.argmax(logits, dim=1)\n",
    "        return probas.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, X_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in X_loader:\n",
    "            inputs = inputs.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "            targets = targets.view(-1,1).to(DEVICE)\n",
    "            logits = model.forward(inputs)\n",
    "            predicted = torch.argmax(logits, dim=1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets.view(-1)).sum().item()\n",
    "        accuracy = correct / total * 100\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "def compute_loss(model, X_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for inputs, targets in X_loader:\n",
    "            inputs = inputs.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "            targets = targets.view(-1,1).to(DEVICE)\n",
    "            logits = model.forward(inputs)\n",
    "            loss = F.cross_entropy(logits, targets.view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(X_loader)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = set_logger('BaggingClassifier')\n",
    "\n",
    "# model = torchensemble.bagging.BaggingClassifier(estimator=MLP, n_estimators=10,cuda=False)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# model.set_criterion(criterion)\n",
    "\n",
    "# model.set_optimizer('Adam', lr=1e-3, weight_decay=5e-4)\n",
    "# model.set_scheduler('StepLR', step_size=3)\n",
    "\n",
    "# model.fit(\n",
    "#     train_loader,\n",
    "#     epochs=10,\n",
    "#     test_loader=test_loader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log will be saved in 'c:\\Users\\hp\\Downloads\\Data for WARP\\logs'.\n",
      "Start logging into file c:\\Users\\hp\\Downloads\\Data for WARP\\logs\\BaggingClassifier-2024_05_30_14_27.log...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [16, 3], got [16]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# criterion = nn.CrossEntropyLoss()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# model.set_criterion(criterion)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mset_optimizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchensemble\\bagging.py:196\u001b[0m, in \u001b[0;36mBaggingClassifier.fit\u001b[1;34m(self, train_loader, epochs, log_interval, test_loader, save_model, save_dir)\u001b[0m\n\u001b[0;32m    193\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParallelization on the training epoch: \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(msg\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[1;32m--> 196\u001b[0m rets \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_fit_per_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcur_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m estimators, optimizers \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator, optimizer \u001b[38;5;129;01min\u001b[39;00m rets:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchensemble\\bagging.py:55\u001b[0m, in \u001b[0;36m_parallel_fit_per_epoch\u001b[1;34m(train_loader, estimator, cur_lr, optimizer, criterion, idx, epoch, log_interval, device, is_classification)\u001b[0m\n\u001b[0;32m     53\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     54\u001b[0m output \u001b[38;5;241m=\u001b[39m estimator(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m---> 55\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [16, 3], got [16]"
     ]
    }
   ],
   "source": [
    "logger = set_logger('BaggingClassifier')\n",
    "\n",
    "model = torchensemble.bagging.BaggingClassifier(estimator=MLP, n_estimators=10,cuda=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.set_criterion(criterion)\n",
    "\n",
    "model.set_optimizer('Adam', lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=50,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model initialization\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MLP()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "\n",
    "train_acc_data = []\n",
    "train_cost_data = []\n",
    "test_acc_data = []\n",
    "test_cost_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21072\\3132252864.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100 | train_loss: 2.8453 | train_accuracy: 10.42 || test_loss: 2.8528 | tset_accuracy: 10.42\n",
      "epoch: 2/100 | train_loss: 2.4555 | train_accuracy: 38.66 || test_loss: 2.5122 | tset_accuracy: 40.62\n",
      "epoch: 3/100 | train_loss: 2.1841 | train_accuracy: 47.22 || test_loss: 2.2421 | tset_accuracy: 50.00\n",
      "epoch: 4/100 | train_loss: 1.9015 | train_accuracy: 50.93 || test_loss: 1.9524 | tset_accuracy: 50.00\n",
      "epoch: 5/100 | train_loss: 1.7099 | train_accuracy: 52.78 || test_loss: 1.8305 | tset_accuracy: 51.04\n",
      "epoch: 6/100 | train_loss: 1.5219 | train_accuracy: 54.17 || test_loss: 1.5570 | tset_accuracy: 57.29\n",
      "epoch: 7/100 | train_loss: 1.3962 | train_accuracy: 54.40 || test_loss: 1.4376 | tset_accuracy: 56.25\n",
      "epoch: 8/100 | train_loss: 1.2549 | train_accuracy: 56.25 || test_loss: 1.3276 | tset_accuracy: 55.21\n",
      "epoch: 9/100 | train_loss: 1.1703 | train_accuracy: 58.10 || test_loss: 1.2778 | tset_accuracy: 53.12\n",
      "epoch: 10/100 | train_loss: 1.1161 | train_accuracy: 59.72 || test_loss: 1.1763 | tset_accuracy: 53.12\n",
      "epoch: 11/100 | train_loss: 1.0620 | train_accuracy: 59.03 || test_loss: 1.1550 | tset_accuracy: 51.04\n",
      "epoch: 12/100 | train_loss: 1.0360 | train_accuracy: 58.56 || test_loss: 1.1637 | tset_accuracy: 52.08\n",
      "epoch: 13/100 | train_loss: 1.0151 | train_accuracy: 59.72 || test_loss: 1.0971 | tset_accuracy: 61.46\n",
      "epoch: 14/100 | train_loss: 0.9800 | train_accuracy: 60.88 || test_loss: 1.0857 | tset_accuracy: 57.29\n",
      "epoch: 15/100 | train_loss: 0.9492 | train_accuracy: 61.34 || test_loss: 1.0797 | tset_accuracy: 53.12\n",
      "epoch: 16/100 | train_loss: 0.9394 | train_accuracy: 60.65 || test_loss: 1.0572 | tset_accuracy: 56.25\n",
      "epoch: 17/100 | train_loss: 0.9086 | train_accuracy: 63.66 || test_loss: 1.0791 | tset_accuracy: 50.00\n",
      "epoch: 18/100 | train_loss: 0.8913 | train_accuracy: 63.19 || test_loss: 1.0556 | tset_accuracy: 53.12\n",
      "epoch: 19/100 | train_loss: 0.8765 | train_accuracy: 62.96 || test_loss: 1.0117 | tset_accuracy: 50.00\n",
      "epoch: 20/100 | train_loss: 0.8582 | train_accuracy: 65.51 || test_loss: 1.0178 | tset_accuracy: 51.04\n",
      "epoch: 21/100 | train_loss: 0.8478 | train_accuracy: 65.74 || test_loss: 0.9667 | tset_accuracy: 51.04\n",
      "epoch: 22/100 | train_loss: 0.8480 | train_accuracy: 64.81 || test_loss: 0.9755 | tset_accuracy: 55.21\n",
      "epoch: 23/100 | train_loss: 0.8277 | train_accuracy: 64.81 || test_loss: 1.0199 | tset_accuracy: 54.17\n",
      "epoch: 24/100 | train_loss: 0.8158 | train_accuracy: 67.82 || test_loss: 1.0101 | tset_accuracy: 54.17\n",
      "epoch: 25/100 | train_loss: 0.8036 | train_accuracy: 66.20 || test_loss: 1.0386 | tset_accuracy: 54.17\n",
      "epoch: 26/100 | train_loss: 0.7966 | train_accuracy: 65.74 || test_loss: 0.9796 | tset_accuracy: 52.08\n",
      "epoch: 27/100 | train_loss: 0.7880 | train_accuracy: 67.36 || test_loss: 1.0105 | tset_accuracy: 53.12\n",
      "epoch: 28/100 | train_loss: 0.7910 | train_accuracy: 67.36 || test_loss: 1.0150 | tset_accuracy: 54.17\n",
      "epoch: 29/100 | train_loss: 0.7847 | train_accuracy: 67.82 || test_loss: 1.0084 | tset_accuracy: 52.08\n",
      "epoch: 30/100 | train_loss: 0.7849 | train_accuracy: 69.91 || test_loss: 0.9907 | tset_accuracy: 51.04\n",
      "epoch: 31/100 | train_loss: 0.7737 | train_accuracy: 69.91 || test_loss: 0.9553 | tset_accuracy: 57.29\n",
      "epoch: 32/100 | train_loss: 0.7659 | train_accuracy: 69.91 || test_loss: 1.0479 | tset_accuracy: 55.21\n",
      "epoch: 33/100 | train_loss: 0.7669 | train_accuracy: 69.91 || test_loss: 1.0074 | tset_accuracy: 52.08\n",
      "epoch: 34/100 | train_loss: 0.7607 | train_accuracy: 71.30 || test_loss: 0.9445 | tset_accuracy: 52.08\n",
      "epoch: 35/100 | train_loss: 0.7498 | train_accuracy: 71.30 || test_loss: 0.9902 | tset_accuracy: 57.29\n",
      "epoch: 36/100 | train_loss: 0.7494 | train_accuracy: 71.30 || test_loss: 0.9973 | tset_accuracy: 53.12\n",
      "epoch: 37/100 | train_loss: 0.7394 | train_accuracy: 70.60 || test_loss: 1.0303 | tset_accuracy: 55.21\n",
      "epoch: 38/100 | train_loss: 0.7353 | train_accuracy: 71.30 || test_loss: 0.9336 | tset_accuracy: 57.29\n",
      "epoch: 39/100 | train_loss: 0.7317 | train_accuracy: 69.68 || test_loss: 1.0119 | tset_accuracy: 55.21\n",
      "epoch: 40/100 | train_loss: 0.7259 | train_accuracy: 73.15 || test_loss: 0.9629 | tset_accuracy: 56.25\n",
      "epoch: 41/100 | train_loss: 0.7217 | train_accuracy: 71.30 || test_loss: 1.0022 | tset_accuracy: 47.92\n",
      "epoch: 42/100 | train_loss: 0.7192 | train_accuracy: 73.84 || test_loss: 0.9885 | tset_accuracy: 51.04\n",
      "epoch: 43/100 | train_loss: 0.7244 | train_accuracy: 72.69 || test_loss: 0.9750 | tset_accuracy: 51.04\n",
      "epoch: 44/100 | train_loss: 0.7201 | train_accuracy: 73.84 || test_loss: 0.9867 | tset_accuracy: 56.25\n",
      "epoch: 45/100 | train_loss: 0.7159 | train_accuracy: 73.61 || test_loss: 0.9809 | tset_accuracy: 54.17\n",
      "epoch: 46/100 | train_loss: 0.7017 | train_accuracy: 73.84 || test_loss: 0.9885 | tset_accuracy: 55.21\n",
      "epoch: 47/100 | train_loss: 0.7036 | train_accuracy: 74.31 || test_loss: 0.9935 | tset_accuracy: 52.08\n",
      "epoch: 48/100 | train_loss: 0.6974 | train_accuracy: 73.84 || test_loss: 1.0103 | tset_accuracy: 47.92\n",
      "epoch: 49/100 | train_loss: 0.6896 | train_accuracy: 76.85 || test_loss: 1.0020 | tset_accuracy: 51.04\n",
      "epoch: 50/100 | train_loss: 0.7007 | train_accuracy: 74.54 || test_loss: 0.9474 | tset_accuracy: 51.04\n",
      "epoch: 51/100 | train_loss: 0.6791 | train_accuracy: 74.31 || test_loss: 0.9652 | tset_accuracy: 53.12\n",
      "epoch: 52/100 | train_loss: 0.6912 | train_accuracy: 74.77 || test_loss: 1.0092 | tset_accuracy: 52.08\n",
      "epoch: 53/100 | train_loss: 0.6726 | train_accuracy: 76.85 || test_loss: 1.0166 | tset_accuracy: 53.12\n",
      "epoch: 54/100 | train_loss: 0.6788 | train_accuracy: 76.62 || test_loss: 0.9622 | tset_accuracy: 51.04\n",
      "epoch: 55/100 | train_loss: 0.6737 | train_accuracy: 76.62 || test_loss: 0.9448 | tset_accuracy: 53.12\n",
      "epoch: 56/100 | train_loss: 0.6600 | train_accuracy: 77.78 || test_loss: 0.9686 | tset_accuracy: 57.29\n",
      "epoch: 57/100 | train_loss: 0.6599 | train_accuracy: 78.70 || test_loss: 0.9294 | tset_accuracy: 57.29\n",
      "epoch: 58/100 | train_loss: 0.6518 | train_accuracy: 77.08 || test_loss: 0.9585 | tset_accuracy: 55.21\n",
      "epoch: 59/100 | train_loss: 0.6477 | train_accuracy: 77.78 || test_loss: 0.9840 | tset_accuracy: 56.25\n",
      "epoch: 60/100 | train_loss: 0.6439 | train_accuracy: 78.47 || test_loss: 0.9485 | tset_accuracy: 52.08\n",
      "epoch: 61/100 | train_loss: 0.6356 | train_accuracy: 79.40 || test_loss: 0.9836 | tset_accuracy: 54.17\n",
      "epoch: 62/100 | train_loss: 0.6449 | train_accuracy: 77.31 || test_loss: 0.9777 | tset_accuracy: 53.12\n",
      "epoch: 63/100 | train_loss: 0.6200 | train_accuracy: 79.40 || test_loss: 0.9411 | tset_accuracy: 55.21\n",
      "epoch: 64/100 | train_loss: 0.6296 | train_accuracy: 80.09 || test_loss: 0.9541 | tset_accuracy: 50.00\n",
      "epoch: 65/100 | train_loss: 0.6284 | train_accuracy: 80.09 || test_loss: 1.0156 | tset_accuracy: 54.17\n",
      "epoch: 66/100 | train_loss: 0.6103 | train_accuracy: 80.09 || test_loss: 1.0175 | tset_accuracy: 53.12\n",
      "epoch: 67/100 | train_loss: 0.6154 | train_accuracy: 78.24 || test_loss: 0.9810 | tset_accuracy: 52.08\n",
      "epoch: 68/100 | train_loss: 0.6033 | train_accuracy: 82.87 || test_loss: 1.0182 | tset_accuracy: 58.33\n",
      "epoch: 69/100 | train_loss: 0.5783 | train_accuracy: 81.25 || test_loss: 0.9748 | tset_accuracy: 52.08\n",
      "epoch: 70/100 | train_loss: 0.5973 | train_accuracy: 83.10 || test_loss: 0.9852 | tset_accuracy: 46.88\n",
      "epoch: 71/100 | train_loss: 0.5851 | train_accuracy: 81.94 || test_loss: 1.0000 | tset_accuracy: 46.88\n",
      "epoch: 72/100 | train_loss: 0.5815 | train_accuracy: 83.80 || test_loss: 1.0363 | tset_accuracy: 50.00\n",
      "epoch: 73/100 | train_loss: 0.5902 | train_accuracy: 82.64 || test_loss: 0.9819 | tset_accuracy: 47.92\n",
      "epoch: 74/100 | train_loss: 0.5763 | train_accuracy: 83.33 || test_loss: 1.0352 | tset_accuracy: 52.08\n",
      "epoch: 75/100 | train_loss: 0.5790 | train_accuracy: 84.26 || test_loss: 1.0093 | tset_accuracy: 52.08\n",
      "epoch: 76/100 | train_loss: 0.5660 | train_accuracy: 83.10 || test_loss: 0.9716 | tset_accuracy: 47.92\n",
      "epoch: 77/100 | train_loss: 0.5537 | train_accuracy: 83.33 || test_loss: 1.0627 | tset_accuracy: 51.04\n",
      "epoch: 78/100 | train_loss: 0.5515 | train_accuracy: 84.49 || test_loss: 1.0546 | tset_accuracy: 51.04\n",
      "epoch: 79/100 | train_loss: 0.5459 | train_accuracy: 84.72 || test_loss: 1.0040 | tset_accuracy: 52.08\n",
      "epoch: 80/100 | train_loss: 0.5485 | train_accuracy: 82.64 || test_loss: 1.0199 | tset_accuracy: 53.12\n",
      "epoch: 81/100 | train_loss: 0.5339 | train_accuracy: 85.42 || test_loss: 1.0935 | tset_accuracy: 50.00\n",
      "epoch: 82/100 | train_loss: 0.5420 | train_accuracy: 81.94 || test_loss: 1.0673 | tset_accuracy: 53.12\n",
      "epoch: 83/100 | train_loss: 0.5406 | train_accuracy: 84.72 || test_loss: 1.0525 | tset_accuracy: 48.96\n",
      "epoch: 84/100 | train_loss: 0.5301 | train_accuracy: 84.26 || test_loss: 1.0573 | tset_accuracy: 47.92\n",
      "epoch: 85/100 | train_loss: 0.5380 | train_accuracy: 83.33 || test_loss: 1.0465 | tset_accuracy: 54.17\n",
      "epoch: 86/100 | train_loss: 0.5193 | train_accuracy: 84.95 || test_loss: 1.0559 | tset_accuracy: 52.08\n",
      "epoch: 87/100 | train_loss: 0.5144 | train_accuracy: 84.03 || test_loss: 1.0622 | tset_accuracy: 56.25\n",
      "epoch: 88/100 | train_loss: 0.5011 | train_accuracy: 86.57 || test_loss: 1.0776 | tset_accuracy: 56.25\n",
      "epoch: 89/100 | train_loss: 0.4924 | train_accuracy: 83.56 || test_loss: 1.1025 | tset_accuracy: 50.00\n",
      "epoch: 90/100 | train_loss: 0.4952 | train_accuracy: 86.81 || test_loss: 1.0715 | tset_accuracy: 54.17\n",
      "epoch: 91/100 | train_loss: 0.5030 | train_accuracy: 86.34 || test_loss: 1.0142 | tset_accuracy: 50.00\n",
      "epoch: 92/100 | train_loss: 0.4895 | train_accuracy: 84.95 || test_loss: 1.0820 | tset_accuracy: 48.96\n",
      "epoch: 93/100 | train_loss: 0.4918 | train_accuracy: 86.34 || test_loss: 1.1030 | tset_accuracy: 52.08\n",
      "epoch: 94/100 | train_loss: 0.4829 | train_accuracy: 85.65 || test_loss: 1.0518 | tset_accuracy: 44.79\n",
      "epoch: 95/100 | train_loss: 0.4955 | train_accuracy: 86.11 || test_loss: 1.0409 | tset_accuracy: 45.83\n",
      "epoch: 96/100 | train_loss: 0.4642 | train_accuracy: 87.27 || test_loss: 1.0818 | tset_accuracy: 51.04\n",
      "epoch: 97/100 | train_loss: 0.4562 | train_accuracy: 89.81 || test_loss: 1.1058 | tset_accuracy: 55.21\n",
      "epoch: 98/100 | train_loss: 0.4730 | train_accuracy: 87.27 || test_loss: 1.0457 | tset_accuracy: 50.00\n",
      "epoch: 99/100 | train_loss: 0.4686 | train_accuracy: 88.43 || test_loss: 1.0571 | tset_accuracy: 46.88\n",
      "epoch: 100/100 | train_loss: 0.4597 | train_accuracy: 86.57 || test_loss: 1.1030 | tset_accuracy: 50.00\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "    \n",
    "        inputs = torch.tensor(inputs)\n",
    "        inputs = inputs.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "        targets = targets.view(-1).to(DEVICE)\n",
    "\n",
    "        logits = model.forward(inputs.view(-1, NUM_FEATURES))\n",
    "\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        train_loss = compute_loss(model, train_loader)\n",
    "        test_loss = compute_loss(model, test_loader)\n",
    "        train_acc = compute_accuracy(model, train_loader)\n",
    "        test_acc = compute_accuracy(model, test_loader)\n",
    "\n",
    "        train_acc_data.append(train_acc)\n",
    "        test_acc_data.append(test_acc)\n",
    "        train_cost_data.append(train_loss)\n",
    "        test_cost_data.append(test_loss)\n",
    "\n",
    "        scheduler.step(train_acc_data[-1])\n",
    "\n",
    "        print(f\"epoch: {epoch+1}/{NUM_EPOCHS}\", end=\"\")\n",
    "        print(\" | train_loss: %.4f\" %train_loss, end = \"\")\n",
    "        print(\" | train_accuracy: %.2f\" %train_acc, end = \"\")\n",
    "        print(\" || test_loss: %.4f\" %test_loss, end = \"\")\n",
    "        print(\" | tset_accuracy: %.2f\" %test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_cost_data)), train_cost_data, color = 'blue')\n",
    "plt.plot(range(len(test_cost_data)), test_cost_data, color = 'red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('cost')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_acc_data)), train_acc_data, color = 'blue')\n",
    "plt.plot(range(len(test_acc_data)), test_acc_data, color = 'red')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_network.1.weight tensor([[ 0.5076, -0.5901,  0.2843,  ..., -0.1907, -0.3901, -0.3999],\n",
      "        [ 0.0890,  0.5172, -0.1965,  ..., -0.4658,  0.2894,  0.0036],\n",
      "        [ 0.3389,  0.3078,  0.0270,  ..., -0.3899, -0.2789,  0.0310],\n",
      "        ...,\n",
      "        [ 0.2020, -0.2153, -0.2074,  ...,  0.4475, -0.4474,  0.1184],\n",
      "        [-0.0951, -0.0031,  0.1041,  ..., -0.1745,  0.3957,  0.1520],\n",
      "        [-0.1400, -0.2422, -0.1330,  ..., -0.0969, -0.1333,  0.4141]])\n",
      "my_network.1.bias tensor([-3.5834e-05, -2.7864e-06, -1.0891e-05,  1.3599e-05, -1.6383e-06,\n",
      "        -3.5730e-05, -1.7359e-05,  2.1998e-06,  1.8978e-06,  6.0732e-06,\n",
      "        -7.3911e-06,  2.0087e-05,  3.6690e-06,  6.3895e-07, -9.1991e-06,\n",
      "         1.1151e-05, -1.7297e-05,  1.6503e-05, -4.9539e-06, -4.3420e-06,\n",
      "         1.8355e-05, -1.2764e-06,  1.1749e-06,  8.2731e-06, -4.6626e-05,\n",
      "        -5.6163e-06, -6.2116e-06,  4.4494e-05, -3.4378e-05, -4.3989e-06,\n",
      "        -1.0860e-05, -1.0819e-05, -4.5639e-06,  2.9557e-05, -1.0338e-05,\n",
      "         3.0501e-06,  5.1996e-05,  3.1471e-06,  7.4428e-06, -8.5249e-06,\n",
      "         1.2332e-05, -6.7484e-07,  1.6755e-05,  1.4945e-06,  9.6482e-06,\n",
      "        -3.1870e-05,  1.0805e-05, -1.4704e-05, -1.9712e-05, -1.6577e-06,\n",
      "        -3.3052e-05, -1.6648e-05,  1.1775e-05, -1.6412e-06, -8.1030e-06,\n",
      "         6.9965e-08,  5.8978e-06,  3.8951e-06,  2.7206e-05,  7.3965e-06,\n",
      "         3.4313e-05,  1.6819e-06,  4.9524e-06, -6.3010e-06,  6.4490e-06,\n",
      "         2.1800e-05,  6.8445e-06,  8.6294e-06, -8.9875e-06,  8.9698e-06,\n",
      "         5.6653e-06, -3.0636e-05,  1.6131e-05,  1.1255e-05,  1.6230e-05,\n",
      "        -5.9064e-06,  5.4829e-06, -1.6858e-07,  5.3485e-06, -2.2462e-06,\n",
      "        -5.8153e-06,  3.5775e-05, -4.4363e-06,  2.0611e-06, -6.6561e-06,\n",
      "        -1.0145e-05, -4.2503e-06,  2.9302e-06, -1.1592e-06, -2.3191e-07,\n",
      "         3.8267e-06, -2.7854e-06,  7.3103e-06, -4.0797e-05, -2.1842e-05,\n",
      "        -1.8769e-05, -1.0649e-05,  1.4477e-05, -3.8908e-06,  3.7302e-06,\n",
      "        -2.2058e-05,  8.2664e-06,  3.3332e-05, -9.0628e-08,  4.9519e-06,\n",
      "         6.6869e-06,  1.8737e-05,  1.7770e-05,  2.0832e-05, -1.4468e-05,\n",
      "         1.0915e-05, -7.1652e-08,  3.0094e-05, -1.1223e-05, -1.4628e-05,\n",
      "        -6.7959e-06, -3.3571e-06,  9.2814e-06,  8.0574e-06, -1.6039e-05,\n",
      "        -6.3805e-06, -1.3449e-05,  1.8920e-05, -2.4574e-06, -5.0813e-06,\n",
      "        -9.0307e-06, -5.7082e-06, -1.2074e-06])\n",
      "my_network.2.weight tensor([0.9577, 0.8338, 0.8858, 0.9613, 0.7876, 0.8726, 0.7986, 0.9080, 0.7603,\n",
      "        0.8536, 0.9744, 0.8625, 0.8875, 0.8535, 0.8534, 0.8868, 0.8116, 0.9141,\n",
      "        0.9448, 0.8132, 0.8405, 0.7823, 0.9227, 0.8260, 0.9241, 0.7943, 0.8802,\n",
      "        0.9029, 0.8309, 0.8407, 0.9677, 0.8096, 0.8914, 0.8375, 0.8914, 0.9846,\n",
      "        0.8137, 0.8941, 0.8658, 0.9059, 0.8617, 0.8674, 0.8318, 0.8363, 0.8791,\n",
      "        0.8235, 0.9203, 0.8353, 0.8820, 0.9063, 0.8761, 0.8306, 0.8005, 0.9336,\n",
      "        0.9445, 0.8429, 0.9100, 0.8091, 0.8410, 0.8872, 0.8783, 0.9424, 0.8260,\n",
      "        0.8173, 0.8804, 0.9105, 0.8998, 0.8539, 0.7715, 0.8048, 0.9964, 0.9143,\n",
      "        0.8574, 0.8461, 0.8387, 0.7934, 0.8747, 1.0258, 0.8359, 0.8143, 0.8711,\n",
      "        0.9276, 0.7427, 0.8742, 0.8044, 0.8543, 0.8943, 0.8711, 0.8906, 0.8052,\n",
      "        0.9638, 0.7307, 0.7978, 0.7787, 0.8982, 0.8524, 0.7970, 0.8917, 0.8585,\n",
      "        0.7800, 0.8220, 0.8923, 0.8899, 0.8235, 0.8678, 0.8348, 0.8316, 0.8068,\n",
      "        0.8363, 0.8948, 0.8672, 0.7769, 0.9351, 0.8218, 0.8339, 0.8692, 0.8373,\n",
      "        0.9080, 0.9014, 0.8754, 0.8076, 0.9884, 0.7664, 0.8308, 0.9865, 0.9041,\n",
      "        0.7808, 0.7898])\n",
      "my_network.2.bias tensor([ 1.3734e-01, -7.3706e-03, -7.8147e-02, -1.2580e-01, -6.7968e-02,\n",
      "         9.7643e-03, -6.8231e-02,  9.3669e-03, -6.7359e-02, -4.9860e-02,\n",
      "         1.3093e-03, -2.1293e-02, -9.8361e-02, -6.0692e-02,  5.8880e-02,\n",
      "        -3.6180e-02, -3.9391e-02, -9.2649e-02, -1.3448e-01, -8.6394e-02,\n",
      "        -7.3374e-02, -1.3605e-01,  4.6252e-02, -1.1515e-01, -5.7518e-04,\n",
      "        -8.4414e-02, -2.7868e-02,  3.6429e-03, -1.4257e-02, -4.5400e-02,\n",
      "        -1.4973e-02, -8.8549e-02, -5.3833e-02, -7.1671e-02, -3.3035e-02,\n",
      "         2.6544e-02, -1.1854e-01,  1.1148e-01, -3.0442e-03, -1.3483e-01,\n",
      "        -5.4163e-03, -3.2749e-02, -1.0796e-01, -3.3426e-02, -8.8625e-02,\n",
      "        -4.8583e-02,  1.9603e-03,  1.8768e-02, -8.5402e-02,  6.0312e-02,\n",
      "        -6.5529e-02, -2.2877e-02, -7.8333e-02,  1.2131e-02, -1.4546e-02,\n",
      "        -9.7532e-02, -9.4418e-02, -1.1389e-01,  1.2993e-02, -4.3865e-02,\n",
      "        -9.0899e-02, -3.5161e-02,  4.1472e-02, -7.4915e-02, -1.3180e-01,\n",
      "        -1.0898e-01,  7.0381e-05, -9.3832e-02, -4.4483e-02, -1.0810e-01,\n",
      "         1.2635e-02,  3.2537e-03, -6.7304e-02,  4.9607e-03, -6.3474e-02,\n",
      "        -1.1172e-01,  1.1273e-02,  1.8454e-02, -4.5565e-02,  3.4560e-02,\n",
      "        -4.7912e-02, -2.2441e-02, -6.5472e-02, -2.3415e-02, -4.2677e-02,\n",
      "         9.0133e-03, -6.5165e-02,  9.4870e-02, -4.4399e-02,  1.2964e-02,\n",
      "         4.8282e-02, -8.3465e-02, -3.3767e-02, -1.2537e-01, -3.3974e-02,\n",
      "         4.8899e-02, -3.8861e-02,  5.6847e-02, -2.9034e-02, -1.3067e-01,\n",
      "        -1.6001e-02,  4.2109e-02, -1.0370e-01, -7.9107e-02, -6.3739e-04,\n",
      "        -4.3381e-02, -7.8534e-02, -5.1920e-03, -6.4429e-02, -6.2039e-03,\n",
      "         2.7535e-02, -5.7235e-02,  4.8671e-02, -1.5038e-02, -1.1312e-01,\n",
      "         3.0322e-02, -1.2069e-03, -3.3004e-02, -5.8172e-02, -2.7654e-02,\n",
      "        -6.6342e-02, -6.3482e-02, -1.3267e-02, -9.2045e-02, -1.0565e-02,\n",
      "        -2.7896e-02, -7.0556e-02, -9.9734e-02])\n",
      "my_network.5.weight tensor([[ 0.0895,  0.0253, -0.0830,  ..., -0.0593,  0.0518,  0.0206],\n",
      "        [-0.0571, -0.0891,  0.1168,  ...,  0.0287, -0.0333, -0.0945],\n",
      "        [-0.1439, -0.0447, -0.0984,  ..., -0.0066, -0.0889, -0.0689],\n",
      "        ...,\n",
      "        [ 0.1038,  0.0636, -0.1294,  ..., -0.0810,  0.0821, -0.0254],\n",
      "        [-0.1113, -0.0053, -0.1377,  ..., -0.0235,  0.0306, -0.1371],\n",
      "        [ 0.2146,  0.1736, -0.1157,  ...,  0.0192,  0.0849,  0.0748]])\n",
      "my_network.5.bias tensor([-3.4608e-05,  1.3404e-05, -3.7394e-05, -9.0400e-06,  3.0970e-05,\n",
      "         6.2153e-06, -2.1637e-05,  1.3848e-06,  7.2483e-06,  1.2992e-09,\n",
      "        -2.6403e-05, -4.1332e-05, -1.5071e-05,  5.4836e-06, -9.3288e-06,\n",
      "        -4.3194e-06, -3.8787e-05,  2.6574e-05, -7.2918e-06, -8.9876e-06,\n",
      "        -1.0703e-05,  1.9981e-07, -1.6752e-05, -4.3998e-06,  3.2721e-05,\n",
      "        -4.8997e-06, -3.2821e-07, -2.4640e-05,  2.5430e-05,  8.3010e-06,\n",
      "        -2.0483e-05, -1.4440e-05,  5.8994e-06, -6.4946e-06,  2.3907e-05,\n",
      "        -2.5661e-05, -1.7244e-05,  2.6026e-05, -2.2796e-05, -2.7877e-05,\n",
      "        -6.3194e-06,  7.2104e-06, -1.1035e-05,  8.2754e-06, -2.6073e-06,\n",
      "        -2.3781e-05, -1.9319e-05,  1.8414e-05,  2.0401e-05, -3.3720e-06,\n",
      "         5.8934e-06,  3.0210e-05,  1.3874e-06, -4.6433e-06,  3.0746e-05,\n",
      "        -1.1047e-05, -6.0970e-06,  2.4605e-06,  6.2938e-06,  1.0395e-05,\n",
      "         5.8697e-06,  2.7357e-05, -3.8649e-05,  1.0445e-05,  1.5979e-06,\n",
      "        -1.0186e-05,  7.7680e-06,  2.4699e-05, -7.9642e-06,  4.1352e-06,\n",
      "        -1.1260e-05,  5.9119e-06,  2.6104e-05, -8.3908e-06, -1.3636e-05,\n",
      "        -1.8455e-06,  4.6049e-06,  5.1523e-07,  1.5080e-05, -1.4898e-05,\n",
      "         4.3400e-05,  2.1078e-05, -1.5448e-05, -2.8452e-05,  2.5645e-05,\n",
      "         2.8565e-08,  2.5853e-05,  1.1765e-05,  9.3061e-06, -1.6513e-05,\n",
      "        -9.0053e-06,  1.4037e-05,  9.0133e-06,  9.5410e-06,  2.7218e-06,\n",
      "        -1.9812e-05,  1.5295e-05,  2.0359e-05, -3.4874e-05, -1.3210e-05,\n",
      "        -3.2408e-05,  1.6810e-05,  6.5032e-06, -8.3660e-06, -1.2644e-05,\n",
      "         3.7788e-05,  1.8769e-05,  1.2398e-06,  2.7313e-06, -2.4836e-05,\n",
      "        -4.5049e-05, -2.5336e-05, -2.2207e-05, -3.9188e-06, -1.0652e-05,\n",
      "        -6.1298e-06,  6.0176e-06,  1.8182e-05,  1.4076e-05, -1.6781e-05,\n",
      "        -2.1524e-05, -9.8268e-06,  7.4103e-06,  1.8273e-05,  2.9886e-05,\n",
      "        -1.0818e-05,  6.7600e-06,  4.4387e-05,  2.0730e-05,  1.5893e-05,\n",
      "         1.3315e-05, -1.5166e-05,  1.4834e-05, -1.6049e-06, -7.4750e-06,\n",
      "        -4.7863e-06, -2.8187e-06, -1.6992e-05,  4.3284e-05, -2.9067e-06,\n",
      "         1.7225e-05, -2.3016e-05, -3.5496e-06,  7.0885e-06, -4.0518e-06,\n",
      "        -1.4086e-06, -1.0570e-05, -2.2360e-06,  3.4676e-05, -1.0269e-05,\n",
      "         2.6879e-05,  2.5614e-05,  2.6074e-05, -5.4052e-06, -6.5405e-05,\n",
      "         1.3696e-05, -2.7265e-05, -1.8972e-05, -1.9722e-05, -3.6749e-06,\n",
      "         1.7377e-05, -7.6059e-06,  3.8976e-06,  1.6828e-05, -1.2102e-05,\n",
      "        -2.9889e-06, -3.0405e-05,  3.1287e-05,  1.4994e-05,  7.6173e-06,\n",
      "        -2.4048e-05,  1.7765e-05,  2.8509e-06, -1.4204e-05, -3.2411e-05,\n",
      "         1.9507e-05, -1.8041e-05, -2.7635e-05, -1.1435e-05, -1.4889e-05,\n",
      "         1.8253e-05,  1.6533e-05,  1.1279e-06,  3.1759e-06, -5.9054e-06,\n",
      "        -5.0963e-06,  1.3831e-05, -2.3454e-06, -2.2566e-05, -1.2216e-06,\n",
      "         7.2793e-06, -4.8450e-05,  3.0343e-07, -1.6304e-05,  2.0791e-05,\n",
      "        -6.1915e-06, -8.7080e-07, -2.6555e-06, -2.0229e-05, -3.5643e-06,\n",
      "        -2.1373e-05, -2.2576e-05, -6.4710e-06, -2.1423e-05, -2.1394e-05,\n",
      "         5.1760e-06, -9.7557e-06, -1.1338e-05, -1.5524e-06,  1.6265e-05,\n",
      "         3.4980e-06,  1.4864e-05, -3.5905e-05, -3.7088e-06,  8.8481e-06,\n",
      "        -2.7506e-05,  1.8395e-06, -3.1997e-05, -2.3426e-06,  5.1448e-06,\n",
      "         3.7326e-05,  4.0600e-06,  1.2239e-05, -7.9234e-06,  2.4554e-05,\n",
      "         2.5566e-06,  1.2012e-05, -1.6003e-05, -6.6931e-05,  2.6908e-05,\n",
      "         3.7961e-05,  1.9516e-05, -9.9089e-06, -1.0392e-05,  1.5721e-05,\n",
      "        -1.7996e-05, -2.9080e-05,  6.3445e-06,  1.8423e-05, -5.7975e-06,\n",
      "         3.2090e-05, -2.5759e-05, -2.3305e-05, -5.3552e-06,  5.9491e-06,\n",
      "        -1.0054e-05,  1.4184e-05,  1.0471e-06,  3.7611e-05,  1.2689e-05,\n",
      "        -7.3736e-06, -5.1096e-06, -1.2196e-06,  7.1582e-06,  1.6338e-05,\n",
      "         6.6708e-06])\n",
      "my_network.6.weight tensor([0.7648, 0.7801, 0.8087, 0.8345, 0.8724, 0.8729, 0.7981, 0.7341, 0.8407,\n",
      "        0.7725, 0.8378, 0.7982, 0.7976, 0.7014, 0.8767, 0.7116, 0.7221, 0.8107,\n",
      "        0.9480, 0.7395, 0.7051, 0.6793, 0.7403, 0.7147, 0.7644, 0.7770, 0.8465,\n",
      "        0.7507, 0.7757, 0.7993, 0.7548, 0.7772, 0.7414, 0.7646, 0.8617, 0.8295,\n",
      "        0.6918, 0.7953, 0.7455, 0.7919, 0.7512, 0.8561, 0.7874, 0.7858, 0.7378,\n",
      "        0.8030, 0.7336, 0.7575, 0.7708, 0.7165, 0.7383, 0.8018, 0.7082, 0.8177,\n",
      "        0.7721, 0.7641, 0.7982, 0.9250, 0.7242, 0.7986, 0.7934, 0.7775, 0.9293,\n",
      "        0.8101, 0.8942, 0.7279, 0.8053, 0.7527, 0.7832, 0.8211, 0.7450, 0.7068,\n",
      "        0.7003, 0.8010, 0.8209, 0.8472, 0.7628, 0.7510, 0.7266, 0.7851, 0.7806,\n",
      "        0.7303, 0.7089, 0.7156, 0.7283, 0.7924, 0.7463, 0.7144, 0.8215, 0.7639,\n",
      "        0.7845, 0.7340, 0.7377, 0.8603, 0.7271, 0.8194, 0.7238, 0.7022, 0.8177,\n",
      "        0.7808, 0.7694, 0.7890, 0.8933, 0.8202, 0.8737, 0.7745, 0.7917, 0.8632,\n",
      "        0.8422, 0.7510, 0.8036, 0.7152, 0.6996, 0.6898, 0.7090, 0.7642, 0.7392,\n",
      "        0.7713, 0.7593, 0.7633, 0.7605, 0.7853, 0.8611, 0.7481, 0.7975, 0.7984,\n",
      "        0.7323, 0.8096, 0.7563, 0.7886, 0.7100, 0.8075, 0.7057, 0.7713, 0.7186,\n",
      "        0.7505, 0.7328, 0.7629, 0.8416, 0.7337, 0.7170, 0.8045, 0.7833, 0.9363,\n",
      "        0.7807, 0.8290, 0.7067, 0.7966, 0.8160, 0.8038, 0.8278, 0.7668, 0.8037,\n",
      "        0.6250, 0.7595, 0.7561, 0.8048, 0.8258, 0.8281, 0.7404, 0.8813, 0.7826,\n",
      "        0.7204, 0.7671, 0.8274, 0.7161, 0.7816, 0.8239, 0.7515, 0.7638, 0.8011,\n",
      "        0.6989, 0.7779, 0.7852, 0.8393, 0.6859, 0.7061, 0.7793, 0.8227, 0.7779,\n",
      "        0.6550, 0.7165, 0.7272, 0.7352, 0.7530, 0.8563, 0.7551, 0.8285, 0.7688,\n",
      "        0.7540, 0.7661, 0.7832, 0.7833, 0.8275, 0.7470, 0.7691, 0.7777, 0.7888,\n",
      "        0.7949, 0.7734, 0.7922, 0.8210, 0.7534, 0.8243, 0.6801, 0.7293, 0.7090,\n",
      "        0.7774, 0.7569, 0.7927, 0.7618, 0.7722, 0.7357, 0.7757, 0.7230, 0.7857,\n",
      "        0.8452, 0.8296, 0.8305, 0.7831, 0.7960, 0.7764, 0.8456, 0.7247, 0.7170,\n",
      "        0.7039, 0.8094, 0.7893, 0.8138, 0.8273, 0.7970, 0.7667, 0.7860, 0.7364,\n",
      "        0.7804, 0.7447, 0.8242, 0.7951, 0.7833, 0.7417, 0.7847, 0.6951, 0.8062,\n",
      "        0.7807, 0.7575, 0.7361, 0.7688, 0.7464, 0.8179, 0.7138, 0.7650, 0.8032,\n",
      "        0.8744, 0.8176, 0.7973, 0.7454])\n",
      "my_network.6.bias tensor([-0.0972, -0.0026, -0.0155,  0.0016,  0.0156,  0.0284, -0.0286, -0.0754,\n",
      "        -0.0404,  0.0170, -0.0364, -0.0364, -0.0143, -0.0373, -0.0473, -0.0627,\n",
      "        -0.0432, -0.0295, -0.0346,  0.0175, -0.0784, -0.0463, -0.0068, -0.0643,\n",
      "        -0.0679, -0.0287,  0.0100, -0.0191, -0.0214, -0.0651, -0.0716, -0.0832,\n",
      "        -0.0924, -0.0378, -0.0287, -0.0187, -0.0753, -0.0319, -0.0436, -0.0408,\n",
      "        -0.0721, -0.0076, -0.0048, -0.0163, -0.0434, -0.0207, -0.0325, -0.0158,\n",
      "        -0.0230, -0.0122, -0.0632, -0.0800, -0.0442, -0.0452, -0.1029, -0.0572,\n",
      "        -0.0151,  0.0056, -0.0671, -0.0338, -0.0021, -0.0751, -0.0032,  0.0656,\n",
      "        -0.0232, -0.0383, -0.0065, -0.0731,  0.0252, -0.0283, -0.0193, -0.0308,\n",
      "        -0.0809, -0.0567, -0.0078, -0.0232, -0.0159, -0.0206,  0.0045,  0.0035,\n",
      "        -0.0786, -0.0654, -0.0341, -0.0189, -0.0016, -0.0606, -0.0463, -0.0690,\n",
      "        -0.0614, -0.0211,  0.0024, -0.0598,  0.0004, -0.0332, -0.0496,  0.0012,\n",
      "        -0.0216, -0.0569, -0.0210, -0.0712, -0.0156,  0.0360,  0.0800,  0.0331,\n",
      "        -0.0247, -0.0326, -0.0220, -0.0468, -0.0592,  0.0121, -0.0217, -0.0509,\n",
      "        -0.0464, -0.0398, -0.0464,  0.0185, -0.0190, -0.0899, -0.1101,  0.0039,\n",
      "        -0.0277, -0.1352,  0.0082, -0.0037,  0.0250, -0.0211, -0.0575, -0.0587,\n",
      "        -0.0504, -0.0103, -0.0756, -0.0554, -0.0121, -0.0673, -0.0473,  0.0383,\n",
      "        -0.1006, -0.0262, -0.0150, -0.0433, -0.0764, -0.0371,  0.0348,  0.0006,\n",
      "        -0.0426,  0.0432, -0.0931, -0.0283,  0.0544,  0.0030,  0.0663, -0.0262,\n",
      "        -0.0374, -0.0816, -0.0755, -0.0120, -0.0741, -0.0161, -0.0440, -0.0173,\n",
      "         0.0003, -0.0120, -0.0289,  0.0093, -0.0019, -0.0306,  0.0360, -0.0528,\n",
      "        -0.0082, -0.0606, -0.0148, -0.0443, -0.0299, -0.0615, -0.1059, -0.0933,\n",
      "        -0.1214, -0.0987, -0.0118, -0.0406, -0.0976, -0.1015, -0.0323, -0.0249,\n",
      "        -0.0180, -0.0635, -0.0650, -0.0352,  0.0287,  0.0168, -0.0084, -0.0891,\n",
      "         0.0379,  0.0082, -0.0148, -0.0240, -0.0460, -0.0635, -0.0293, -0.0452,\n",
      "        -0.0454,  0.0141, -0.0410, -0.0371, -0.0765, -0.0728, -0.0371,  0.0209,\n",
      "        -0.0505, -0.0299, -0.0011, -0.0707, -0.0881,  0.0155, -0.0341, -0.0995,\n",
      "        -0.0003, -0.0587,  0.0402, -0.0213, -0.0288, -0.0353, -0.0213, -0.0211,\n",
      "        -0.0392, -0.0111, -0.0857, -0.0229, -0.0286, -0.0756, -0.0243, -0.0249,\n",
      "         0.0048, -0.0653, -0.0078, -0.0010, -0.1008,  0.0142, -0.0673, -0.0165,\n",
      "        -0.0361, -0.0168, -0.0312, -0.0505, -0.0309, -0.0280, -0.0113, -0.0721,\n",
      "        -0.0913, -0.0267, -0.0603, -0.0279,  0.0178, -0.0398,  0.0037, -0.0741])\n",
      "my_network.9.weight tensor([[ 0.0005, -0.0754, -0.1016,  ...,  0.0608,  0.0775, -0.0846],\n",
      "        [-0.0715,  0.0346,  0.0018,  ..., -0.0609, -0.0023,  0.0379],\n",
      "        [ 0.0017,  0.0951, -0.0412,  ...,  0.0595, -0.0451,  0.1107],\n",
      "        ...,\n",
      "        [-0.0029, -0.0605,  0.0690,  ..., -0.0893, -0.0175, -0.0315],\n",
      "        [-0.0582, -0.1066,  0.0346,  ..., -0.0193,  0.0162,  0.0484],\n",
      "        [ 0.0499, -0.1037,  0.0194,  ..., -0.0848,  0.0315, -0.0160]])\n",
      "my_network.9.bias tensor([-1.5773e-05,  4.0331e-06,  1.8323e-05, -3.5969e-06, -1.3747e-05,\n",
      "        -2.1838e-05, -7.7378e-06,  9.2881e-06, -3.0193e-05, -2.5208e-07,\n",
      "         3.5745e-05, -7.2964e-07, -1.1334e-05,  2.0535e-05,  1.5313e-05,\n",
      "         9.3768e-06,  2.8061e-05, -1.3876e-06,  1.3620e-06, -3.6138e-05,\n",
      "         2.5049e-05,  6.4272e-06, -4.5907e-05,  2.3759e-06, -1.6264e-05,\n",
      "        -1.0564e-05,  2.1261e-05, -9.2710e-06,  4.7981e-06,  2.3501e-05,\n",
      "        -2.0961e-05, -1.2912e-05,  7.8552e-06,  1.0551e-05,  2.0984e-05,\n",
      "         1.5175e-05,  2.3226e-05,  5.8817e-06,  2.7803e-05, -4.6934e-06,\n",
      "         1.0844e-05, -2.7076e-05,  6.7979e-06, -6.8220e-06, -6.1318e-05,\n",
      "        -8.7468e-06,  3.4880e-05,  1.4010e-05, -5.5243e-07, -1.1329e-05,\n",
      "         5.6299e-05, -5.4477e-06,  9.8715e-06,  1.6430e-05,  2.1213e-05,\n",
      "        -2.6592e-05, -2.0104e-05, -1.6342e-06,  7.8846e-06, -6.8773e-06,\n",
      "         2.3901e-05, -8.1329e-06, -2.9637e-06, -1.3585e-05,  5.3649e-06,\n",
      "         9.6717e-06,  1.0562e-05, -4.2122e-06,  1.7026e-06, -2.3002e-06,\n",
      "        -2.0133e-05, -4.5295e-05,  4.6667e-05, -8.1538e-06,  1.0741e-05,\n",
      "         3.9215e-06, -3.1110e-05, -1.3749e-05, -6.6933e-06,  2.7841e-05,\n",
      "         1.0004e-05,  2.0234e-05,  2.0682e-05,  1.4911e-05, -1.6396e-05,\n",
      "         2.1022e-05, -8.6193e-06, -4.0083e-06, -1.4241e-05, -3.6748e-06,\n",
      "         1.5958e-06, -2.7666e-05,  5.8284e-06, -5.2103e-06,  1.6089e-05,\n",
      "         4.2730e-06, -2.0132e-05,  2.5089e-05,  1.3498e-05, -3.1755e-05,\n",
      "         1.0039e-05,  1.2997e-05,  3.5386e-05, -1.0801e-05,  3.0033e-07,\n",
      "        -1.1183e-05, -6.3384e-06,  1.1382e-05, -3.9083e-06, -1.0627e-05,\n",
      "        -7.0829e-06, -1.2757e-05, -2.0962e-05,  4.3336e-05,  1.6642e-05,\n",
      "         2.7212e-05, -6.9725e-06, -3.1705e-05,  1.0280e-05,  7.6715e-06,\n",
      "        -9.9236e-06, -2.9178e-05,  1.6945e-05,  7.9751e-06, -1.4390e-06,\n",
      "        -2.6660e-05,  1.8262e-06,  5.6513e-06])\n",
      "my_network.10.weight tensor([0.8306, 0.7784, 0.8659, 0.7992, 0.8133, 0.8098, 0.8105, 0.8033, 0.8595,\n",
      "        0.8621, 0.8367, 0.8032, 0.8142, 0.8107, 0.8276, 0.8430, 0.7580, 0.6872,\n",
      "        0.7445, 0.8861, 0.7952, 0.8100, 0.8893, 0.8772, 0.8285, 0.8396, 0.7619,\n",
      "        0.7817, 0.8139, 0.8554, 0.8648, 0.8071, 0.8763, 0.7837, 0.7977, 0.8273,\n",
      "        0.7689, 0.9167, 0.8011, 0.9104, 0.7654, 0.7817, 0.8160, 0.8452, 0.7928,\n",
      "        0.8053, 0.8154, 0.7900, 0.8773, 0.7989, 0.8579, 0.8264, 0.8493, 0.7718,\n",
      "        0.7705, 0.9305, 0.7617, 0.8452, 0.8457, 0.7410, 0.8286, 0.8206, 0.7045,\n",
      "        0.7281, 0.8580, 0.7802, 0.7661, 0.8090, 0.8138, 0.8104, 0.8226, 0.7611,\n",
      "        0.8432, 0.8087, 0.7665, 0.8422, 0.7832, 0.8367, 0.7833, 0.8441, 0.8000,\n",
      "        0.8324, 0.8169, 0.7764, 0.7997, 0.8415, 0.8525, 0.7839, 0.8379, 0.9025,\n",
      "        0.8195, 0.8007, 0.9032, 0.8812, 0.8618, 0.8733, 0.7564, 0.7592, 0.8445,\n",
      "        0.9092, 0.7306, 0.7632, 0.7444, 0.7677, 0.9193, 0.8341, 0.8113, 0.8415,\n",
      "        0.7921, 0.7864, 0.7525, 0.8892, 0.8098, 0.9023, 0.7960, 0.7939, 0.7505,\n",
      "        0.8335, 0.8898, 0.8075, 0.8094, 0.8492, 0.8641, 0.8027, 0.7452, 0.8635,\n",
      "        0.9810, 0.7494])\n",
      "my_network.10.bias tensor([-0.0382, -0.0887, -0.0117, -0.0362,  0.0142,  0.0112,  0.0854, -0.0225,\n",
      "         0.0517,  0.0078,  0.0156, -0.0105,  0.0030, -0.0422, -0.0369, -0.0289,\n",
      "        -0.0147, -0.0920, -0.0624,  0.0474, -0.0512, -0.0386, -0.0146,  0.0057,\n",
      "        -0.0190, -0.0390, -0.0170, -0.0365, -0.0224,  0.0279,  0.0114,  0.0279,\n",
      "         0.0411, -0.0214, -0.0203, -0.0677, -0.0628,  0.0019, -0.0075,  0.0039,\n",
      "        -0.0674, -0.0385, -0.0352,  0.0505, -0.0193, -0.0628, -0.0042,  0.0408,\n",
      "         0.0599, -0.0569,  0.0477, -0.0236, -0.0017, -0.0256, -0.0272,  0.0134,\n",
      "        -0.0468, -0.0166, -0.0079, -0.0016,  0.0187, -0.0194, -0.0624, -0.0448,\n",
      "        -0.0232, -0.0652, -0.0344, -0.0599,  0.0040, -0.0303, -0.0348, -0.0091,\n",
      "         0.0552, -0.0011, -0.0176,  0.0052, -0.0923,  0.0550, -0.0413, -0.0089,\n",
      "        -0.0435,  0.0055, -0.0183, -0.0102, -0.0101,  0.0009, -0.0376, -0.0029,\n",
      "         0.0269,  0.0119,  0.0240, -0.0148,  0.0278,  0.0663,  0.0222,  0.0224,\n",
      "        -0.0598, -0.0159,  0.0044, -0.0106, -0.0547, -0.0463, -0.0504, -0.0325,\n",
      "        -0.0198,  0.0103, -0.0326,  0.0016, -0.0189,  0.0220, -0.0194,  0.0112,\n",
      "        -0.0108,  0.0411, -0.0188, -0.0403, -0.0603,  0.0027,  0.0397, -0.0382,\n",
      "        -0.0483,  0.0590, -0.0230, -0.0366, -0.0769,  0.0101,  0.0424, -0.0071])\n",
      "my_network.13.weight tensor([[-0.0430,  0.1552,  0.0333,  ..., -0.0530,  0.1632, -0.0038],\n",
      "        [-0.1607,  0.1415,  0.1499,  ...,  0.1323,  0.0144, -0.1489],\n",
      "        [ 0.0772,  0.0005,  0.0246,  ...,  0.0544,  0.0877, -0.1348],\n",
      "        ...,\n",
      "        [-0.0181, -0.1405,  0.0679,  ...,  0.1440, -0.0876,  0.0501],\n",
      "        [ 0.0960, -0.0672, -0.0413,  ..., -0.1557, -0.1114,  0.0911],\n",
      "        [-0.0595,  0.1007,  0.1576,  ...,  0.1697, -0.0283, -0.1098]])\n",
      "my_network.13.bias tensor([ 1.4751e-05, -9.7394e-06, -1.0494e-05, -2.7245e-06,  2.1257e-06,\n",
      "         3.7672e-06, -1.0093e-05, -1.4262e-06,  1.8581e-05,  6.2413e-06,\n",
      "        -2.1617e-05,  3.0920e-05, -5.0828e-06, -5.1439e-06, -1.8957e-05,\n",
      "        -2.1070e-05,  2.8291e-05, -6.1829e-06, -1.0418e-05,  9.8060e-06,\n",
      "        -1.5959e-05,  1.2166e-05,  6.8468e-06, -1.6043e-06,  7.9513e-06,\n",
      "         1.6551e-07,  1.7932e-05, -1.0784e-05,  1.8693e-08, -2.7857e-05,\n",
      "         5.8117e-06,  3.1946e-05, -2.9452e-05, -2.1179e-05, -1.9890e-05,\n",
      "        -7.6735e-06,  9.2923e-07, -1.4339e-05,  4.3222e-06, -7.2853e-06,\n",
      "         3.4872e-06,  2.4844e-05,  1.1192e-05, -4.4435e-05, -2.2812e-05,\n",
      "         1.1380e-05,  1.3477e-05,  3.9999e-06,  5.3953e-06,  2.0680e-06,\n",
      "         3.2504e-05, -5.7162e-06,  2.3406e-05, -8.6579e-06,  1.2645e-05,\n",
      "        -2.6485e-05,  1.7105e-05,  2.8744e-05,  2.4713e-05,  9.5770e-06,\n",
      "        -1.8938e-05, -2.3088e-06,  1.0553e-06,  2.9424e-05])\n",
      "my_network.14.weight tensor([0.7713, 0.8911, 0.8704, 0.8753, 0.9462, 0.9032, 0.8295, 0.8208, 0.8348,\n",
      "        0.8663, 0.8301, 0.9539, 0.8537, 0.8761, 0.8489, 0.8131, 0.8464, 0.9128,\n",
      "        0.9400, 0.7656, 0.8562, 0.8890, 0.8173, 0.8076, 0.9797, 0.8961, 0.8718,\n",
      "        0.7869, 0.8273, 0.8719, 0.9153, 0.9212, 0.8909, 0.8231, 0.8537, 0.7315,\n",
      "        0.9707, 0.7337, 0.9193, 0.8879, 0.7561, 0.8168, 0.7667, 0.7110, 0.7759,\n",
      "        0.7943, 0.8931, 0.9325, 0.7780, 0.8329, 0.9145, 0.8780, 0.7223, 0.7959,\n",
      "        0.8309, 0.7663, 0.7721, 0.8484, 0.8295, 0.9070, 0.8611, 0.8469, 0.8356,\n",
      "        0.8699])\n",
      "my_network.14.bias tensor([-3.2336e-02,  8.5741e-03, -7.6013e-03,  7.2959e-02, -9.6273e-03,\n",
      "         5.4218e-02,  1.2338e-02, -6.7796e-02, -3.0020e-02,  7.4287e-03,\n",
      "         1.5391e-02,  1.3475e-01,  1.2500e-02, -1.1941e-04, -7.7904e-03,\n",
      "        -6.0400e-02,  3.4373e-02,  8.5168e-02,  6.5086e-02, -5.3256e-02,\n",
      "        -1.5490e-02, -2.0738e-03,  3.3814e-02, -4.1129e-02,  6.5789e-02,\n",
      "        -1.3230e-03, -1.6365e-03, -4.6757e-02, -2.5682e-02,  4.1450e-02,\n",
      "         8.5417e-02,  8.4627e-02,  3.4426e-02, -3.0228e-02,  7.0147e-02,\n",
      "        -6.0888e-02,  8.1660e-02, -2.8614e-02,  5.7347e-02,  5.2262e-02,\n",
      "        -3.8019e-02,  2.6786e-02,  3.4306e-03, -8.9687e-02, -2.2451e-02,\n",
      "         2.6257e-04,  5.6443e-02,  6.5849e-02, -4.7604e-02,  1.3739e-03,\n",
      "         6.6156e-02,  5.4850e-02, -2.8445e-02, -2.1805e-02, -1.9606e-02,\n",
      "        -3.9374e-02, -4.7801e-02,  4.6051e-02,  1.5485e-02,  4.1341e-02,\n",
      "         3.1641e-02, -2.0847e-02,  3.2153e-03,  5.1377e-03])\n",
      "my_network.17.weight tensor([[-0.2231, -0.0474,  0.1328,  ..., -0.0785,  0.0727, -0.1878],\n",
      "        [-0.0404, -0.2115, -0.0687,  ..., -0.2176,  0.1244,  0.0824],\n",
      "        [-0.0877,  0.0799, -0.0806,  ..., -0.0350, -0.0804,  0.1731],\n",
      "        ...,\n",
      "        [ 0.1050, -0.1444, -0.2291,  ...,  0.2082,  0.1672, -0.0780],\n",
      "        [ 0.2118, -0.1660,  0.1091,  ..., -0.1616, -0.1032, -0.1783],\n",
      "        [ 0.1169, -0.2141,  0.1070,  ..., -0.1211, -0.3394, -0.0234]])\n",
      "my_network.17.bias tensor([-4.1477e-06, -1.8612e-06,  2.3880e-05, -8.3620e-06, -2.3301e-06,\n",
      "        -3.9282e-06,  4.1213e-06,  1.5551e-05, -2.1126e-06,  1.2564e-05,\n",
      "        -2.6440e-07, -6.9977e-06, -1.1437e-05,  1.0998e-06,  1.8168e-05,\n",
      "         7.2904e-05, -3.5395e-07,  8.7275e-06,  1.4729e-05, -3.8694e-06,\n",
      "        -5.8192e-06, -1.8911e-05,  1.2929e-06,  3.1503e-05,  1.3897e-05,\n",
      "        -3.9090e-06, -1.8520e-05, -2.0215e-05, -3.9573e-06,  1.0731e-05,\n",
      "         1.1193e-05,  1.4110e-05])\n",
      "my_network.18.weight tensor([1.2024, 1.2189, 0.8501, 1.0539, 1.0162, 1.0287, 1.1499, 0.9253, 1.1621,\n",
      "        0.8825, 0.8192, 1.1479, 0.9341, 1.1552, 0.7414, 1.0353, 0.8102, 0.9049,\n",
      "        0.9986, 0.7997, 0.8353, 1.0786, 1.0712, 0.9511, 0.9181, 0.7469, 0.7297,\n",
      "        0.7347, 1.0152, 1.2490, 0.8669, 1.1127])\n",
      "my_network.18.bias tensor([ 8.4806e-01,  5.7547e-01,  3.1237e-02,  3.6166e-01,  2.1601e-01,\n",
      "         2.8304e-01,  6.6958e-01,  1.0461e-01,  7.4230e-01,  8.1176e-02,\n",
      "         7.2540e-02,  3.9835e-01,  2.2414e-01,  5.0987e-01, -1.3127e-01,\n",
      "         3.3605e-01, -1.3640e-04,  1.2243e-01,  3.1185e-01, -8.1153e-02,\n",
      "         5.2373e-02,  3.2044e-01,  3.2077e-01,  2.2242e-01,  1.9787e-01,\n",
      "        -1.2666e-01, -1.5363e-01, -1.6130e-01,  3.3598e-01,  5.8600e-01,\n",
      "         2.3707e-02,  3.6246e-01])\n",
      "my_network.21.weight tensor([[ 2.2504e-01,  3.6753e-01, -7.7758e-02,  3.1133e-01,  4.1660e-01,\n",
      "         -1.7207e-01,  1.6411e-01, -2.9443e-02,  4.1703e-01, -3.1609e-02,\n",
      "          1.9671e-01,  1.4894e-01,  3.7033e-01,  2.9151e-01, -1.9999e-01,\n",
      "          4.5327e-01, -2.7138e-02,  1.9185e-01,  4.1689e-01, -2.1493e-01,\n",
      "          6.1099e-02,  4.2549e-02,  3.6497e-01,  1.7857e-01, -7.1807e-02,\n",
      "         -1.4011e-01, -9.4826e-02, -2.1919e-01,  2.4860e-01,  3.9539e-01,\n",
      "          2.9010e-01,  4.5073e-01],\n",
      "        [ 2.1487e-01,  3.5538e-01,  4.9670e-02,  3.7397e-01,  3.5691e-01,\n",
      "          2.8056e-01,  1.4780e-01, -8.9922e-03,  4.0476e-01,  3.4029e-01,\n",
      "         -1.5252e-01,  4.8877e-01,  4.5082e-03,  2.7699e-01, -7.0877e-02,\n",
      "          1.6642e-01,  3.1528e-01,  6.2814e-02,  3.6376e-01, -2.4617e-01,\n",
      "          2.4756e-01,  4.6324e-01,  3.9875e-01, -7.3835e-02,  2.3744e-01,\n",
      "         -3.2945e-02, -1.5687e-01, -4.4327e-02,  8.8124e-02,  4.6027e-01,\n",
      "          1.3086e-01,  1.3443e-01],\n",
      "        [ 2.6153e-01,  2.2964e-01,  1.1172e-01,  6.6494e-02,  1.2146e-01,\n",
      "          2.6420e-01,  2.5308e-01,  3.0853e-01,  3.7134e-01,  1.3276e-01,\n",
      "          3.0928e-01,  5.3346e-01,  3.8083e-01,  4.1649e-01,  1.2603e-01,\n",
      "          4.7820e-01,  2.2472e-01, -1.2257e-01,  9.7796e-02, -2.2870e-02,\n",
      "         -7.0878e-03,  5.0359e-01,  6.7417e-02,  2.1875e-01,  3.2869e-01,\n",
      "         -9.5808e-02, -8.9624e-02, -1.6776e-01,  7.7130e-02,  3.6389e-01,\n",
      "         -1.3478e-01,  3.0123e-01],\n",
      "        [-6.5522e-02, -9.3455e-02,  2.8591e-02, -8.4015e-02,  1.2522e-01,\n",
      "          1.9488e-02, -4.5784e-01, -4.4266e-01, -2.1634e-01, -4.0770e-01,\n",
      "         -4.2303e-01,  2.0488e-02, -4.8534e-01,  1.9164e-02,  1.1310e-01,\n",
      "          1.5910e-02, -1.5647e-02, -4.1204e-01, -3.0728e-01, -4.2172e-01,\n",
      "         -2.4354e-01,  3.2158e-03, -4.8346e-01, -1.4477e-01, -4.5519e-01,\n",
      "          5.4417e-02, -1.0410e-01, -1.7572e-01,  3.4328e-02, -2.0768e-01,\n",
      "          6.6067e-02, -1.2631e-01],\n",
      "        [-2.6123e-01, -2.6389e-01, -1.8690e-01, -2.6062e-01, -1.7633e-01,\n",
      "         -1.5619e-01, -1.4997e-01, -1.6469e-01, -1.5984e-01, -1.8050e-01,\n",
      "         -1.4266e-01, -1.5847e-01, -2.3996e-01, -1.4875e-01, -1.3536e-01,\n",
      "         -4.2095e-02, -1.4203e-01, -2.3291e-01, -9.8608e-02, -5.5597e-03,\n",
      "         -1.5608e-02, -2.3900e-01, -2.1214e-01, -1.2677e-01, -2.3221e-01,\n",
      "         -1.0142e-01, -1.7881e-01, -7.7276e-02, -5.7583e-02, -2.6490e-01,\n",
      "         -1.4530e-01, -2.2600e-01],\n",
      "        [-1.2939e-01, -2.8594e-01, -1.6046e-01, -2.0522e-01, -1.7927e-01,\n",
      "         -2.1665e-01, -1.9640e-01, -1.7832e-02, -1.8324e-01, -8.3770e-02,\n",
      "         -1.2386e-01, -2.2138e-01, -2.5883e-01, -2.3087e-01, -1.0255e-01,\n",
      "         -1.3059e-01, -6.3563e-02, -2.3161e-01, -1.2949e-01, -1.5835e-01,\n",
      "         -1.6530e-01, -2.0788e-01, -1.6379e-01, -2.1086e-01, -1.1696e-01,\n",
      "         -1.5435e-01, -8.9614e-02, -1.5969e-01, -8.7128e-02, -2.4869e-01,\n",
      "         -7.6075e-02, -2.4547e-01],\n",
      "        [-2.6923e-01, -3.0302e-01,  3.8496e-02, -2.6892e-01, -1.8579e-01,\n",
      "         -2.9247e-01, -2.8857e-01, -2.1500e-01, -1.2531e-01, -1.5711e-01,\n",
      "         -1.7142e-01, -1.3830e-01, -1.8039e-02, -2.6988e-01,  6.0920e-03,\n",
      "         -2.6183e-01, -1.7654e-02,  2.6777e-02, -2.3265e-01, -1.5610e-01,\n",
      "         -1.0612e-01, -2.4422e-01, -2.2079e-01, -7.7580e-02,  2.1721e-02,\n",
      "         -1.7729e-01,  2.9100e-03, -1.3252e-01, -2.5695e-01, -1.4020e-01,\n",
      "         -9.1558e-02, -2.3713e-01],\n",
      "        [-3.3580e-01, -3.4000e-01, -1.5631e-01, -2.9282e-01, -7.2291e-02,\n",
      "         -1.5768e-01, -2.4529e-01, -6.7273e-02, -2.4578e-01, -1.8511e-01,\n",
      "         -5.9678e-02, -2.0784e-01, -1.1939e-01, -2.3063e-01,  2.0935e-02,\n",
      "         -2.0835e-01, -1.6940e-01, -1.7717e-01, -1.7250e-01, -1.3814e-01,\n",
      "         -6.6646e-02, -2.9634e-02, -1.4573e-02, -1.6401e-01, -1.9739e-01,\n",
      "         -7.0268e-02, -7.9635e-03, -2.0048e-01, -2.1336e-01, -2.7967e-01,\n",
      "         -6.7910e-02, -1.9350e-01],\n",
      "        [-1.8986e-01, -2.9501e-01, -7.5921e-02, -9.6355e-02, -1.1924e-01,\n",
      "         -2.2902e-01, -3.5170e-01,  2.9413e-02, -9.8882e-02, -1.1297e-01,\n",
      "          2.1615e-02, -8.4861e-02, -2.4044e-01, -1.9098e-01, -1.2782e-01,\n",
      "         -2.0484e-01, -1.5472e-01, -8.9231e-02, -2.0222e-01, -1.9241e-01,\n",
      "         -1.5000e-01, -3.3880e-02, -2.6355e-01, -2.0470e-01, -1.7671e-01,\n",
      "         -5.8896e-02, -1.0904e-01, -1.4550e-01, -2.4446e-01, -3.0106e-01,\n",
      "         -9.5271e-02, -2.3573e-01],\n",
      "        [-3.1430e-01, -3.1791e-01, -1.4940e-01, -1.0141e-02, -1.3056e-01,\n",
      "          9.7238e-03, -2.5324e-01, -1.6177e-01, -2.6438e-01, -3.1425e-02,\n",
      "         -1.8766e-01, -8.6001e-02, -2.5524e-02, -2.9991e-01, -1.1840e-01,\n",
      "         -1.5960e-01, -1.4084e-01, -2.3479e-01, -2.2972e-01, -1.2915e-01,\n",
      "         -1.3083e-01, -2.3925e-01, -2.9713e-01, -2.1581e-01, -1.9728e-01,\n",
      "         -1.3883e-01, -4.5963e-02,  4.8245e-02, -6.3255e-02, -2.9777e-01,\n",
      "          1.6958e-03, -1.4127e-01],\n",
      "        [-3.1602e-01, -1.4469e-01, -9.0533e-02, -2.8759e-01, -4.9355e-02,\n",
      "         -1.2557e-01, -1.8664e-01, -1.6536e-01, -1.0843e-01, -2.0765e-01,\n",
      "         -3.8008e-02, -2.1102e-01, -2.2799e-01, -2.3114e-01, -1.0652e-01,\n",
      "         -1.8759e-01, -6.8284e-02, -2.3217e-01, -2.1008e-01, -1.5667e-01,\n",
      "         -6.0433e-02, -1.5021e-01, -2.8219e-01, -1.8340e-01, -1.9446e-01,\n",
      "          1.7463e-02, -1.4685e-01, -1.3445e-01, -1.3414e-01, -2.1281e-01,\n",
      "         -5.7899e-02, -2.5205e-01],\n",
      "        [-1.9651e-01, -3.2744e-02, -1.4484e-01, -9.0403e-02, -1.7416e-01,\n",
      "         -4.0808e-01, -3.9776e-01, -8.0233e-02, -3.3378e-02, -8.6733e-02,\n",
      "          2.3472e-02, -4.6982e-03, -1.3908e-01, -2.4480e-01,  1.3648e-01,\n",
      "         -1.7916e-01, -2.5684e-01, -3.3177e-01, -1.9459e-01, -1.2902e-01,\n",
      "          1.8179e-02, -2.3447e-01, -1.7134e-01, -3.6383e-02, -2.9733e-01,\n",
      "         -1.7670e-01, -2.3957e-01,  7.5443e-02, -3.4809e-01, -3.0395e-01,\n",
      "         -2.6104e-01, -3.4051e-01],\n",
      "        [-3.4821e-01, -2.3066e-01, -1.3411e-01, -2.5661e-01, -1.0043e-01,\n",
      "         -2.5444e-01, -1.0062e-01, -2.5599e-02, -2.6115e-01, -1.3573e-01,\n",
      "         -3.2806e-02, -1.8916e-01, -1.1032e-01, -2.7664e-01, -1.0928e-01,\n",
      "         -2.0002e-01, -1.6154e-01, -4.7347e-02, -9.7637e-02, -2.1254e-02,\n",
      "         -1.4364e-01, -1.3975e-01, -2.9561e-01, -2.1953e-01, -6.0859e-02,\n",
      "         -8.8074e-02, -1.4411e-01, -5.2001e-02, -2.5624e-01, -2.6161e-01,\n",
      "         -1.1944e-01, -7.5960e-02],\n",
      "        [-4.1252e-01, -2.2534e-01,  1.0261e-01, -3.2523e-01, -1.2698e-01,\n",
      "         -3.1892e-01, -3.1354e-01,  1.0614e-01, -2.6455e-01, -2.6604e-01,\n",
      "         -5.6417e-02, -3.5295e-01,  3.3585e-02,  9.4019e-03, -1.4479e-01,\n",
      "         -7.4785e-02,  1.1145e-01, -1.4630e-01, -3.5838e-01, -2.5146e-01,\n",
      "         -3.3913e-01, -2.6678e-01, -2.6877e-02, -3.3354e-01, -6.0217e-02,\n",
      "          6.8106e-02,  1.0577e-01, -4.0279e-02, -1.6153e-01, -2.7882e-01,\n",
      "         -1.8571e-01, -1.1990e-01],\n",
      "        [-2.8100e-01, -2.7191e-01, -5.6531e-02, -2.1469e-01, -1.6201e-01,\n",
      "         -1.5017e-01, -2.8660e-01,  7.8032e-05, -1.3603e-01, -1.6106e-01,\n",
      "         -1.3471e-01, -2.1248e-01, -1.8756e-01, -2.2656e-01, -9.1715e-02,\n",
      "         -1.7393e-01, -7.9391e-02, -1.7688e-01, -9.1951e-02, -1.4278e-01,\n",
      "         -1.3754e-01, -1.8619e-01, -1.9146e-01, -1.8065e-01, -9.4072e-02,\n",
      "         -4.3832e-02, -9.9346e-02, -1.0052e-01, -1.8013e-01, -2.3143e-01,\n",
      "         -1.0102e-01, -1.5379e-01],\n",
      "        [-2.7999e-01, -2.9849e-01, -9.8730e-02, -2.8318e-01, -1.8227e-01,\n",
      "         -2.1611e-01, -9.7553e-02, -1.3567e-01, -2.5735e-01, -1.7552e-01,\n",
      "         -1.6232e-02, -2.2304e-01, -1.2782e-01, -2.2992e-01, -1.0008e-01,\n",
      "         -1.7359e-01, -1.4153e-01, -9.9230e-02, -1.9799e-01, -9.3238e-02,\n",
      "         -1.4136e-02, -1.9094e-01, -1.5745e-01, -1.4549e-01, -1.7455e-01,\n",
      "         -1.2540e-01, -1.1811e-01, -1.2396e-01, -1.9048e-01, -2.6651e-01,\n",
      "         -8.6939e-02, -7.3999e-02],\n",
      "        [-2.1595e-01, -3.4086e-01, -1.9889e-01, -1.6896e-01,  1.1495e-02,\n",
      "         -1.1134e-02, -4.0774e-01, -1.5585e-01, -2.3701e-01,  8.3736e-02,\n",
      "          6.6303e-02, -2.8582e-01, -1.6188e-01, -3.2711e-01, -1.3216e-01,\n",
      "         -2.9739e-03, -1.0599e-01, -2.3833e-01, -1.6857e-01,  6.6729e-02,\n",
      "          1.5305e-02, -3.3029e-01, -1.7818e-01, -2.2693e-01,  4.9695e-02,\n",
      "         -2.1399e-01, -1.1441e-01,  8.9397e-02, -2.4317e-01, -2.8124e-01,\n",
      "         -1.9877e-01, -2.7241e-01],\n",
      "        [-4.1169e-01, -2.2011e-01, -2.6037e-01, -2.2032e-01, -1.0822e-02,\n",
      "         -3.5111e-01, -1.6645e-01, -1.9004e-01, -3.4821e-01, -1.5431e-01,\n",
      "         -2.4494e-01,  1.3377e-02, -1.0565e-01, -2.9437e-01, -1.5215e-02,\n",
      "          2.5093e-02,  7.6905e-03, -1.2705e-01, -1.3515e-02,  5.7162e-02,\n",
      "         -2.8918e-01, -1.1761e-01, -1.6386e-01, -2.4587e-01, -2.9168e-01,\n",
      "          5.5801e-02,  7.1386e-02, -1.5857e-01, -2.8702e-01, -8.0500e-02,\n",
      "         -2.2611e-01, -3.3943e-01],\n",
      "        [-3.0671e-01, -1.8748e-01, -2.3213e-01, -6.4155e-02,  1.1236e-03,\n",
      "         -1.9962e-01, -3.0473e-01, -1.1875e-01, -3.0902e-01,  2.3828e-02,\n",
      "         -2.0508e-01, -3.8989e-02, -2.4884e-01, -3.0979e-01,  7.0938e-02,\n",
      "         -2.2294e-01, -5.4403e-02, -1.7455e-01, -2.3660e-01, -1.6192e-01,\n",
      "         -2.2782e-01, -2.5711e-01, -2.7457e-01, -1.5805e-01,  1.3975e-02,\n",
      "         -1.9934e-02, -1.5847e-01, -1.6337e-01, -4.7013e-02, -1.1934e-01,\n",
      "         -1.8286e-01, -2.7729e-01],\n",
      "        [-2.8001e-01, -2.3461e-01, -1.4802e-01, -2.6440e-01, -1.8952e-01,\n",
      "         -1.8058e-01, -2.6355e-01, -9.1632e-02, -1.7440e-01, -7.2422e-02,\n",
      "         -1.5044e-02, -1.9523e-01, -2.1271e-01, -2.4797e-01, -8.8647e-02,\n",
      "         -5.1493e-02, -7.8226e-02, -1.1344e-01, -4.4498e-02,  1.4641e-02,\n",
      "         -1.4395e-01, -1.6650e-01, -2.1442e-01, -1.9066e-01, -1.7397e-01,\n",
      "         -1.1010e-01, -7.8909e-02, -1.2401e-01, -1.7269e-01, -2.4795e-01,\n",
      "         -3.3722e-02, -2.1795e-01],\n",
      "        [-2.8317e-01, -3.1102e-01, -6.7895e-02, -4.2971e-01,  8.4500e-02,\n",
      "         -3.6049e-01, -1.1047e-01, -2.4440e-01, -2.3970e-02, -1.2761e-01,\n",
      "         -1.5373e-02, -2.9020e-01, -2.0551e-01, -2.3457e-01, -1.2751e-01,\n",
      "         -2.7466e-01, -1.7378e-01,  3.6557e-02,  1.3041e-02, -2.2915e-01,\n",
      "         -1.5513e-01, -1.0313e-01, -3.7814e-01, -7.8095e-02,  4.4836e-03,\n",
      "         -2.9024e-01,  6.8466e-02,  1.5838e-01, -1.3477e-01, -1.8741e-01,\n",
      "         -2.7991e-01, -2.6681e-01]])\n",
      "my_network.21.bias tensor([ 0.2638,  0.2286,  0.3105, -0.3477, -0.3419, -0.3456, -0.3210, -0.3107,\n",
      "        -0.3340, -0.3186, -0.3313, -0.3308, -0.3219, -0.3108, -0.3375, -0.3253,\n",
      "        -0.3081, -0.3174, -0.3224, -0.3386, -0.3270])\n"
     ]
    }
   ],
   "source": [
    "# Access the weights of the model\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold at the last layer: Parameter containing:\n",
      "tensor([ 0.2638,  0.2286,  0.3105, -0.3477, -0.3419, -0.3456, -0.3210, -0.3107,\n",
      "        -0.3340, -0.3186, -0.3313, -0.3308, -0.3219, -0.3108, -0.3375, -0.3253,\n",
      "        -0.3081, -0.3174, -0.3224, -0.3386, -0.3270], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "threshold = model.my_network[-1].bias\n",
    "print(\"Threshold at the last layer:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     logits, _ = model(X_test)\n",
    "#     predictions = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# # Print confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
